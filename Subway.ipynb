{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saketpram/nyc-subway/blob/main/Subway.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j1AyTKGeHmb",
        "outputId": "0ee366ad-e96d-4d5b-eda4-a40afe67c706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Saket Ram\n",
        "# Collaboration: None\n",
        "# Sources: Used ChatGPT for debugging and plot help, matplotlib documentation,\n",
        "# pandas documentation, numpy documentation, images and data from MTA website\n",
        "\n",
        "# Relevant imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "drive.mount('/content/drive')\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colormaps\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "from scipy.stats import shapiro, ttest_ind, f_oneway, mannwhitneyu\n",
        "import seaborn as sns\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# Global variables for file loading and zip extraction\n",
        "realTimeData = \"/content/drive/My Drive/ENGR 1050 Final Project/02 19 Data/stop_times.txt\"\n",
        "stops = \"/content/drive/My Drive/ENGR 1050 Final Project/02 19 Data/stops.txt\"\n",
        "# zipFile = '/content/drive/My Drive/ENGR 1050 Final Project/02 19 Data/gtfs.zip'\n",
        "# endLoc = '/content/drive/My Drive/ENGR 1050 Final Project/02 19 Data'\n",
        "\n",
        "def readData(link):\n",
        "  \"\"\"Imports CSV as a dataframe with the first column of the spreadsheet\n",
        "  set to row indices\"\"\"\n",
        "  df = pd.read_csv(link, header=0, index_col=0)\n",
        "  return df\n",
        "\n",
        "# Set df and stopsDf as global variable so the dataframe does not need to be read from CSV multiple times\n",
        "# (it is a large file)\n",
        "df = readData(realTimeData)\n",
        "stopsDf = readData(stops)\n",
        "\n",
        "def extract(link, endLoc):\n",
        "  \"\"\"Extracts all files from zip file at location link and sends them to the folder\n",
        "  specified by endLoc.\"\"\"\n",
        "  with zipfile.ZipFile(link, 'r') as zip_ref:\n",
        "      zip_ref.extractall(endLoc)\n",
        "\n",
        "  # Return nothing\n",
        "  return\n",
        "\n",
        "def subwayLineQuery(df, line, direction):\n",
        "  \"\"\"Takes in dataframe with realtime subway data, string representing subway line,\n",
        "  and string representing direction. Returns dataframe with rows that\n",
        "  correspond to weekdays, the line specified by the user, and the direction\n",
        "  specified by the user.\"\"\"\n",
        "\n",
        "  # Uses unique code to extract trains that bear the 6X designation\n",
        "  if line == '6X':\n",
        "\n",
        "    # Train names that serve as unique identifiers for the 6X\n",
        "    joinedString1 = f\"{line[0]}..{direction}02\"\n",
        "    joinedString2 = f\"{line[0]}..{direction}08\"\n",
        "\n",
        "    # Filters by weekday and ensures only rows remaining are rows associated with 6X\n",
        "    filteredDf1 = df.query(f'trip_id.str.contains(\"Weekday\")', engine='python')\n",
        "    filteredDf = filteredDf1.query(f'trip_id.str.contains(\"_{joinedString1}\") or trip_id.str.contains(\"_{joinedString2}\")', engine='python')\n",
        "\n",
        "  # 6 train\n",
        "  elif line == '6':\n",
        "\n",
        "    # Removes 6X trains using similar filtering logic as above\n",
        "    joinedString1 = f\"{line}..{direction}02\"\n",
        "    joinedString2 = f\"{line[0]}..{direction}08\"\n",
        "    filteredDf1 = df[~df.index.str.contains(f\"_{joinedString1}\")]\n",
        "    filteredDf2 = filteredDf1[~filteredDf1.index.str.contains(f\"_{joinedString2}\")]\n",
        "\n",
        "    # In this filtered dataframe, only preserves rows associated with the 6 train\n",
        "    joinedString = f\"{line}..{direction}\"\n",
        "    filteredDf = filteredDf2.query(f'trip_id.str.contains(\"Weekday\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # 7 train\n",
        "  elif line == '7':\n",
        "\n",
        "    # Removes 7X trains\n",
        "    joinedString1 = f\"{line}..N97X\"\n",
        "    joinedString2 = f\"{line}..S98X\"\n",
        "    filteredDf1 = df[~df.index.str.contains(f\"_{joinedString1}\")]\n",
        "    filteredDf2 = filteredDf1[~filteredDf1.index.str.contains(f\"_{joinedString2}\")]\n",
        "\n",
        "    # Only preserves rows associated with 7 train\n",
        "    joinedString = f\"{line}..{direction}\"\n",
        "    filteredDf = filteredDf2.query(f'trip_id.str.contains(\"L0S1\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # 7X train\n",
        "  elif line == '7X':\n",
        "\n",
        "    # Uses code to extract 7X trains running either northbound or southbound based on direction\n",
        "    # specified when function was called\n",
        "    if direction == 'N':\n",
        "      joinedString = f\"{line[0]}..{direction}97X\"\n",
        "    else:\n",
        "      joinedString = f\"{line[0]}..{direction}98X\"\n",
        "\n",
        "    # Only preserves rows associated with 7X train\n",
        "    filteredDf = df.query(f'trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # Queens Blvd Lines and Nassau Line\n",
        "  elif line == 'E' or line == 'F' or line == 'M' or line == 'R' or line == 'J':\n",
        "\n",
        "    # Only preserves rows associated with E train\n",
        "    joinedString = f\"{line}..{direction}\"\n",
        "    filteredDf = df.query(f'trip_id.str.contains(\"L0S1\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # W train\n",
        "  elif line == 'W':\n",
        "\n",
        "    # Uses code to extract W trains running either northbound or southbound based on direction\n",
        "    # specified when function was called\n",
        "    if direction == 'N':\n",
        "      joinedString = \"N..N72\"\n",
        "    else:\n",
        "      joinedString = \"N..S72\"\n",
        "    filteredDf = df.query(f'trip_id.str.contains(\"Weekday\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # N train\n",
        "  elif line == 'N':\n",
        "\n",
        "    # Removes W trains\n",
        "    joinedString1 = f\"N..N72\"\n",
        "    joinedString2 = f\"N..S72\"\n",
        "    filteredDf1 = df[~df.index.str.contains(f\"_{joinedString1}\")]\n",
        "    filteredDf2 = filteredDf1[~filteredDf1.index.str.contains(f\"_{joinedString2}\")]\n",
        "\n",
        "    # Only preserves rows associated with N train\n",
        "    joinedString = f\"{line}..{direction}\"\n",
        "    filteredDf = filteredDf2.query(f'trip_id.str.contains(\"Weekday\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # All other lines\n",
        "  else:\n",
        "\n",
        "    # Creates string representing unique identifier for specific train line and\n",
        "    # only preserves rows containing that unique identifier\n",
        "    joinedString = f\"{line}..{direction}\"\n",
        "    filteredDf = df.query(f'trip_id.str.contains(\"Weekday\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # Returns filtered dataframe\n",
        "  return filteredDf\n",
        "\n",
        "def getSec(time):\n",
        "  \"\"\"Get total seconds from time of the form HH:MM:SS.\"\"\"\n",
        "  h, m, s = time.split(':')\n",
        "  return int(h) * 3600 + int(m) * 60 + int(s)\n",
        "\n",
        "def addSeconds(df, colList):\n",
        "  \"\"\"Given dataframe with specified list of columns that have time in format HH:MM:SS, adds\n",
        "  that many columns with the same time in seconds format.\"\"\"\n",
        "  for column in colList:\n",
        "    df[f\"{column}_sec\"] = df[column].apply(getSec)\n",
        "  return df\n",
        "\n",
        "def subwayTimeQuery(df, col1, col2, time1, time2):\n",
        "  \"\"\"Given dataframe, two columns, and two time values, creates filtered view of dataframe\n",
        "  that only contains rows between these times.\"\"\"\n",
        "  timeDf = df.query(f'{col1}>={time1} and {col2}<{time2}', engine = 'python')\n",
        "  return timeDf\n",
        "\n",
        "def readBullet(line):\n",
        "  \"\"\"Give the specified train line, loads image of train bullet with OpenCV,\n",
        "  switching the R and B color channels.\"\"\"\n",
        "\n",
        "  # Access image file\n",
        "  bullet = f'/content/drive/My Drive/ENGR 1050 Final Project/02 19 Data/Bullets/{line}_Train.png'\n",
        "  imageColor = cv2.imread(bullet, cv2.IMREAD_COLOR)\n",
        "\n",
        "  if line != 'N' and line != 'Q' and line != 'R' and line != 'W':\n",
        "    # Find all black pixels (each image has a transparent background, which is loaded\n",
        "    # as black)\n",
        "    black_pixels = np.where(\n",
        "        (imageColor[:, :, 0] == 0) &\n",
        "        (imageColor[:, :, 1] == 0) &\n",
        "        (imageColor[:, :, 2] == 0))\n",
        "\n",
        "    # Set black pixels to white\n",
        "    imageColor[black_pixels] = [255, 255, 255]\n",
        "\n",
        "  # Flip R and B channels (because matplotlib does RGB instead of BGR and return flipped image)\n",
        "  imageColor_rgb = cv2.cvtColor(imageColor, cv2.COLOR_BGR2RGB)\n",
        "  return imageColor_rgb\n",
        "\n",
        "def stopExtractor(secondsDf, line, direction):\n",
        "  \"\"\"Creates dictionary that associates each stop ID with a number based on order.\"\"\"\n",
        "\n",
        "  # Creates list of standard lines for which this dictionary can be created easily\n",
        "  stdLines = ['1', '6',  '7', 'C', 'L', 'J', 'W']\n",
        "\n",
        "  # Initializes empty dictionary that will contain keys as stop IDs and values as\n",
        "  # order number that corresponds to each stop\n",
        "  numDict = {}\n",
        "\n",
        "  # Conditional, checks if line is in stdLines or not\n",
        "  if line in stdLines:\n",
        "\n",
        "    # If line is in stdLines, simply sort the stop IDs in the dataframe under\n",
        "    # column 'stop_id'\n",
        "    stopsList = list(dict.fromkeys(secondsDf['stop_id']))\n",
        "    stopsList.sort()\n",
        "\n",
        "  # If the line is 2 train\n",
        "  elif line == '2':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create 2 train route\n",
        "    part0 = ['201'+direction]\n",
        "    part1 = [str(i)+direction for i in range(204,223)]\n",
        "    part2 = [str(i)+direction for i in range(224,228)]\n",
        "    part3 = ['120'+direction, '123'+direction, '127'+direction,\n",
        "             '128'+direction, '132'+direction, '137'+direction]\n",
        "    part4 = [str(i)+direction for i in range(228,240)]\n",
        "    part5 = [str(i)+direction for i in range(241,248)]\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = part0 + part1 + part2 + part3 + part4 + part5\n",
        "\n",
        "    # Perform same dictionary addition steps as previously\n",
        "    numList = np.arange(len(stopsList))\n",
        "    if direction == 'N':\n",
        "      stopsList.reverse()\n",
        "    for i in numList:\n",
        "      numDict[stopsList[i]] = i\n",
        "\n",
        "  # If line is 3 train\n",
        "  elif line == '3':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create 3 train route\n",
        "    part1 = ['301'+direction, '302'+direction]\n",
        "    part2 = [str(i)+direction for i in range(224,228)]\n",
        "    part3 = ['120'+direction, '123'+direction, '127'+direction,\n",
        "             '128'+direction, '132'+direction, '137'+direction]\n",
        "    part4 = [str(i)+direction for i in range(228,240)]\n",
        "    part5 = [str(i)+direction for i in range(248,258)]\n",
        "    stopsList = part1 + part2 + part3 + part4 + part5\n",
        "\n",
        "  # If line is 4 train\n",
        "  elif line == '4':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create 4 train route\n",
        "    part0 = ['401'+direction, '402'+direction]\n",
        "    part1 = [str(i)+direction for i in range(405, 417)]\n",
        "    part2 = ['621'+direction, '626'+direction, '629'+direction, '631'+direction,\n",
        "             '635'+direction, '640'+direction]\n",
        "    part3 = [str(i)+direction for i in range(418, 421)]\n",
        "    part4 = ['423'+direction, '234'+direction, '235'+direction,\n",
        "             '238'+direction, '239'+direction, '250'+direction]\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = part0 + part1 + part2 + part3 + part4\n",
        "\n",
        "  # If line is 5 train\n",
        "  elif line == '5':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create 5 train route\n",
        "    # NOTE: Nereid Av pattern not shown to avoid confusion. 5 trains that terminate\n",
        "    # at 180 St in the graphs produced are assumed to go to Nereid Av\n",
        "    part1 = [str(i)+direction for i in range(501, 506)]\n",
        "    part2 = [str(i)+direction for i in range(213, 223)]\n",
        "    part3 = ['416'+direction, '621'+direction, '626'+direction,\n",
        "             '629'+direction, '631'+direction, '635'+direction,\n",
        "             '640'+direction]\n",
        "    part4 = [str(i)+direction for i in range(418, 421)]\n",
        "    part5 = ['423'+direction, '234'+direction, '235'+direction,\n",
        "             '238'+direction, '239'+direction]\n",
        "    part6 = [str(i)+direction for i in range(241,248)]\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = part1 + part2 + part3 + part4 + part5 + part6\n",
        "\n",
        "  # If train is 6X train\n",
        "  elif line == '6X':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create 6X train route\n",
        "    part1 = [str(i)+direction for i in range(601, 605)]\n",
        "    part2 = [str(i)+direction for i in range(606, 609)]\n",
        "    part3 = ['613'+direction, '619'+direction]\n",
        "    part4 = [str(i)+direction for i in range(621, 641)]\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = part1 + part2 + part3 + part4\n",
        "\n",
        "  # If train is 7X train\n",
        "  elif line == '7X':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create 7X train route\n",
        "    # In 2023, the train is making all stops between Queensboro Plaza and\n",
        "    # 74 St-Rawson, so these stops are included\n",
        "    part1 = ['701'+direction, '702'+direction, '707'+direction]\n",
        "    part2 = [str(i)+direction for i in range(710, 717)]\n",
        "    part3 = [str(i)+direction for i in range(718,722)]\n",
        "    part4 = [str(i)+direction for i in range(723,727)]\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = part1 + part2 + part3 + part4\n",
        "\n",
        "  # If train is A train\n",
        "  elif line == 'A':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create A train route\n",
        "    # Route to Lefferts and to Rockaway Park 116 St ignored to avoid confusion\n",
        "    # A trains terminating at Rockaway Blvd are assumed to go to Lefferts and\n",
        "    # A trains terminating at Broad Channel are assumed to go to 116 St\n",
        "\n",
        "    # Northbound A trains stop at Aqueduct Racetrack, southbound does not\n",
        "    # 135 St included in graphs for both directions because some A trains went\n",
        "    # local and stopped at 135 St\n",
        "    if direction == 'S':\n",
        "      part1 = ['A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A12', 'A14', 'A15',\n",
        "             'A24', 'A27', 'A28', 'A31', 'A32', 'A34', 'A36', 'A38',\n",
        "             'A40', 'A41', 'A42', 'A46', 'A48', 'A51', 'A55', 'A57',\n",
        "             'A59', 'A60', 'A61', 'H02', 'H03', 'H04', 'H06', 'H07',\n",
        "               'H08', 'H09', 'H10', 'H11']\n",
        "    else:\n",
        "      part1 = ['A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A12', 'A14', 'A15',\n",
        "             'A24', 'A27', 'A28', 'A31', 'A32', 'A34', 'A36', 'A38',\n",
        "             'A40', 'A41', 'A42', 'A46', 'A48', 'A51', 'A55', 'A57',\n",
        "             'A59', 'A60', 'A61', 'H01', 'H02', 'H03', 'H04', 'H06', 'H07',\n",
        "               'H08', 'H09', 'H10', 'H11']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = [i+direction for i in part1]\n",
        "\n",
        "  # If train is E train\n",
        "  elif line == 'E':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create E train route\n",
        "    # (Brairwood and 75 Av stops added as some E trains stop at Briarwood)\n",
        "    part1 = ['G05', 'G06',\n",
        "             'G07', 'F05', 'F06', 'F07', 'G08', 'G14', 'G21', 'F09', 'F11', 'F12', 'D14']\n",
        "    part2 = ['A25', 'A27', 'A28', 'A30', 'A31', 'A32', 'A33',\n",
        "             'A34', 'A36', 'A38', 'E01']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = [i+direction for i in part1] + [j+direction for j in part2]\n",
        "\n",
        "  # If train is B train\n",
        "  elif line == 'B':\n",
        "\n",
        "    # Assign stop IDs as specified in the subway map to create B train route\n",
        "    part1 = ['D0'+str(i) for i in range(3,10)]\n",
        "    part2 = ['D'+str(i) for i in range(10,14)]\n",
        "    part3 = ['A'+str(i) for i in range(14,23)]\n",
        "    part4 = ['A24']\n",
        "    part5 = ['D14', 'D15', 'D16', 'D17', 'D20', 'D21', 'D22', 'R30',\n",
        "             'D24', 'D25', 'D26', 'D28', 'D31', 'D35', 'D39', 'D40']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = ([i+direction for i in part1] + [j+direction for j in part2]\n",
        "                 + [k+direction for k in part3] + [l+direction for l in part4]\n",
        "                 + [m+direction for m in part5])\n",
        "\n",
        "  # If train is D train\n",
        "  elif line == 'D':\n",
        "    part1 = ['D01']\n",
        "    part2 = ['D0'+str(i) for i in range(3,10)]\n",
        "    part3 = ['D'+str(i) for i in range(10,14)]\n",
        "    part4 = ['A15', 'A24']\n",
        "\n",
        "    # DeKalb added even though D train does not regularly stop at DeKalb\n",
        "    # (some trains do)\n",
        "    part5 = ['D14', 'D15', 'D16', 'D17', 'D20', 'D21', 'D22', 'R30',\n",
        "             'R31', 'R32', 'R33', 'R34',\n",
        "             'R35', 'R36', 'B12', 'B13', 'B14', 'B15', 'B16',\n",
        "             'B17', 'B18', 'B19', 'B20', 'B21', 'B22', 'B23',\n",
        "             'D43']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = ([i+direction for i in part1] + [j+direction for j in part2]\n",
        "                 + [k+direction for k in part3] + [l+direction for l in part4]\n",
        "                 + [m+direction for m in part5])\n",
        "\n",
        "  # F train\n",
        "  elif line == 'F':\n",
        "    part1 = ['F0'+str(i) for i in range(1,8)]\n",
        "\n",
        "    # NOTE: SERVICE CHANGE DUE TO CONSTRUCTION ON 63 ST LINE\n",
        "    part2 = ['G08', 'G14', 'G21', 'F09', 'F11', 'F12', 'D15',\n",
        "             'D16', 'D17', 'D18', 'D19', 'D20', 'D21', 'F14',\n",
        "             'F15', 'F16', 'F18', 'A41', 'F20', 'F21', 'F22', 'F23',\n",
        "             'F24', 'F25', 'F26', 'F27', 'F29', 'F30', 'F31',\n",
        "             'F32', 'F33', 'F34', 'F35', 'F36', 'F38', 'F39',\n",
        "             'D42', 'D43']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = [i+direction for i in part1] + [j+direction for j in part2]\n",
        "\n",
        "  # M train\n",
        "  elif line == 'M':\n",
        "\n",
        "    # NOTE: SERVICE CHANGE DUE TO CONSTRUCTION ON 63 ST LINE\n",
        "    part1 = ['B10', 'D15',\n",
        "             'D16', 'D17', 'D18', 'D19', 'D20', 'D21',\n",
        "             'M18', 'M16', 'M14', 'M13', 'M12', 'M11', 'M10',\n",
        "             'M09', 'M08', 'M06', 'M05', 'M04', 'M01']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = [i+direction for i in part1]\n",
        "    stopsList.reverse()\n",
        "\n",
        "  # G train\n",
        "  elif line == 'G':\n",
        "    part1 = ['G22', 'G24', 'G26', 'G28', 'G29', 'G30',\n",
        "             'G31', 'G32', 'G33', 'G34', 'G35', 'G36',\n",
        "             'A42', 'F20', 'F21', 'F22', 'F23', 'F24',\n",
        "             'F25', 'F26', 'F27']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = [i+direction for i in part1]\n",
        "\n",
        "  # Q train\n",
        "  elif line == 'Q':\n",
        "    part1 = ['Q05', 'Q04', 'Q03', 'B08', 'R14',\n",
        "             'R16', 'R17', 'R20', 'Q01', 'R30',\n",
        "             'D24', 'D25', 'D26', 'D27', 'D28',\n",
        "             'D29', 'D30', 'D31', 'D32', 'D33',\n",
        "             'D34', 'D35', 'D37', 'D38', 'D39',\n",
        "             'D40', 'D41', 'D42', 'D43']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = [i+direction for i in part1]\n",
        "\n",
        "  # N train\n",
        "  elif line == 'N':\n",
        "    part1 = ['R01', 'R03', 'R04', 'R05', 'R06',\n",
        "              'R08', 'R09', 'R11', 'R13', 'R14',\n",
        "             'R15', 'R16', 'R17', 'R18', 'R19','R20', 'R21',\n",
        "             'R22','R23','Q01','R24',\n",
        "             'R25', 'R26', 'R27', 'R28', 'R29', 'R30',\n",
        "             'R31', 'R32', 'R33', 'R34',\n",
        "             'R35', 'R36', 'R39', 'R40', 'R41', 'N02', 'N03',\n",
        "             'N04', 'N05', 'N06', 'N07', 'N08',\n",
        "             'N09', 'N10', 'D43']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = [i+direction for i in part1]\n",
        "\n",
        "\n",
        "  # R train\n",
        "  elif line == 'R':\n",
        "    part1 = ['G08', 'G09', 'G10', 'G11', 'G12', 'G13', 'G14',\n",
        "             'G15', 'G16', 'G18', 'G19', 'G20', 'G21']\n",
        "    part2 = ['R11', 'R13', 'R14', 'R15', 'R16',\n",
        "             'R17', 'R18', 'R19', 'R20', 'R21', 'R22',\n",
        "             'R23', 'R24', 'R25', 'R26', 'R27', 'R28',\n",
        "             'R29', 'R30', 'R31', 'R32', 'R33', 'R34',\n",
        "             'R35', 'R36', 'R39', 'R40', 'R41', 'R42',\n",
        "             'R43', 'R44', 'R45']\n",
        "\n",
        "    # Combine all lists\n",
        "    stopsList = [i+direction for i in part1] + [j+direction for j in part2]\n",
        "\n",
        "\n",
        "  # Create list from 0 to len(stopsList)\n",
        "  numList = np.arange(len(stopsList))\n",
        "\n",
        "  # If the train is northbound, reverse order of stops\n",
        "  if direction == 'N':\n",
        "    stopsList.reverse()\n",
        "\n",
        "  # Assign each key from stopsList a number from numList\n",
        "  for i in numList:\n",
        "    numDict[stopsList[i]] = i\n",
        "\n",
        "  # Add this dictionary to dataframe\n",
        "  secondsDf['stop_val'] = secondsDf['stop_id'].map(numDict)\n",
        "\n",
        "  # Return dataframe and the dictionary that corresponds each stop ID to\n",
        "  # sequence number\n",
        "  return secondsDf, numDict\n",
        "\n",
        "\n",
        "def stopIDtoName(stopsDf, stopIDlist):\n",
        "  \"\"\"Takes in list of stop IDs, returns dictionary with stop IDs as keys and stop\n",
        "  names as values.\"\"\"\n",
        "\n",
        "  # Creates dictionary with indices of stopDf as keys and stopDf['stop_name'] as\n",
        "  # values\n",
        "  stopNameDict = dict(zip(stopsDf.index, stopsDf['stop_name']))\n",
        "\n",
        "  # Initializes new empty dictionary called stopNames\n",
        "  stopNames = {}\n",
        "\n",
        "  # For each stopID in stopIDlist, finds the real street name of the stop and\n",
        "  # stores it in stopNames dictionary as the value corresponding to the stopID\n",
        "  # key\n",
        "  for stopID in stopIDlist:\n",
        "    stopName = stopNameDict[stopID]\n",
        "    if stopID == 'Q01S' or stopID == 'Q01N':\n",
        "      stopNames[stopID] = 'Canal St (Exp)'\n",
        "    elif stopID == 'R23S' or stopID == 'R23N':\n",
        "      stopNames[stopID] = 'Canal St (Lcl)'\n",
        "    else:\n",
        "      stopNames[stopID] = stopName\n",
        "\n",
        "  # Returns stopNames dictionary\n",
        "  return stopNames\n",
        "\n",
        "def partOne(line, direction, rushHourType):\n",
        "  \"\"\"Given a line, a direction, and the time of day (morning rush or evening rush),\n",
        "  returns\n",
        "  - stopDict, a dictionary corresponding each stop ID to a sequence number\n",
        "  - stopNames, a dictionary corresponding each stop ID to its street name\n",
        "  - timeList, a list of times that will serve as the x-axis of the graph depending\n",
        "  on whether it is morning rush or evening rush\n",
        "  - time1, the time in seconds corresponding to the beginning of morning or evening rush\n",
        "  - time2, the time in seconds corresponding to the  end of morning or evening rush\n",
        "  - filteredSecondsDf, a dataframe for the specific line, time of day, and rush hour type\n",
        "  with each stop arrival being listed in HH:MM:SS as well as just seconds\"\"\"\n",
        "\n",
        "  # Initializes df as a global variable (original dataframe already loaded in)\n",
        "  global df\n",
        "\n",
        "  # Runs subwayLineQuery to filter df by line and direction\n",
        "  subwayDf = subwayLineQuery(df, line, direction)\n",
        "\n",
        "  # Runs addSeconds to ensure stop times are in both HH:MM:SS and seconds\n",
        "  timeDf = addSeconds(subwayDf, ['arrival_time', 'departure_time'])\n",
        "\n",
        "  # If evening, set time1 to be the time in seconds for the beginning of evening rush,\n",
        "  # time2 to be the time in seconds for the end of evening rush, and timeList to be the\n",
        "  # list of times to be sent to the x-axis\n",
        "  if rushHourType == 'evening':\n",
        "    time1 = 55800\n",
        "    time2 = 72000\n",
        "    timeList = ['15:30', '15:45', '16:00', '16:15', '16:30', '16:45', '17:00',\n",
        "                                           '17:15', '17:30', '17:45', '18:00', '18:15', '18:30', '18:45', '19:00',\n",
        "                                           '19:15', '19:30', '19:45', '20:00']\n",
        "\n",
        "  # Do the same for morning rush\n",
        "  else:\n",
        "    time1 = 23400\n",
        "    time2 = 34200\n",
        "    timeList = ['6:30', '6:45', '7:00', '7:15', '7:30',\n",
        "                                          '7:45', '8:00', '8:15', '8:30', '8:45',\n",
        "                                          '9:00', '9:15', '9:30']\n",
        "\n",
        "  # Filter to ensure only stop times between the time for the beginning of rush and the time for\n",
        "  # the end of rush are listed\n",
        "  secondsDf = subwayTimeQuery(timeDf, 'arrival_time_sec', 'departure_time_sec', time1, time2)\n",
        "\n",
        "  # Get the stopDict for a train given direction as well the same secondsDf with an additional column\n",
        "  # containing the stop number in the sequence for the line\n",
        "  filteredSecondsDf, stopDict = stopExtractor(secondsDf, line, direction)\n",
        "\n",
        "  # Initialize global variable stopsDf\n",
        "  global stopsDf\n",
        "\n",
        "  # Get dictionary associating each stopID to its street name\n",
        "  stopNames = stopIDtoName(stopsDf, list(stopDict.keys()))\n",
        "\n",
        "  # Return values as specified\n",
        "  return stopDict, stopNames, timeList, time1, time2, filteredSecondsDf\n",
        "\n",
        "def trainPlot(lines):\n",
        "  \"\"\"Create plot of all the trains that run in both directions during morning\n",
        "  and evening rush. Return nothing.\"\"\"\n",
        "\n",
        "  # Set title weight and axes weight to bold\n",
        "  plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "  plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "  plt.style.use('default')\n",
        "\n",
        "  # Specify list of directions and times\n",
        "  directions = ['S', 'N']\n",
        "  times = ['morning', 'evening']\n",
        "\n",
        "  # Check if there is a rush hour express train variant (only applies to 6X and 7X)\n",
        "  express = False\n",
        "  for line in lines:\n",
        "    if 'X' in line:\n",
        "      express = True\n",
        "      break\n",
        "\n",
        "  # If there is, create a figure that has len(lines)*2-1 rows, 2 columns, with a\n",
        "  # pre-determined figure size (to ensure that all of the train graphs have the same\n",
        "  # figure size)\n",
        "  if express == True:\n",
        "    fig, axs = plt.subplots(len(lines)*2-1, len(directions), figsize=(30, 60*(len(lines)*2-1)/7))\n",
        "  else:\n",
        "    fig, axs = plt.subplots(len(lines)*2, len(directions), figsize=(30, 60*len(lines)*2/7))\n",
        "\n",
        "  # Title graph based on which set of lines is submitted into the function\n",
        "  # (some of the lines just have spaces because these are easier to work with\n",
        "  # when adding the actual train bullets)\n",
        "  # Also specify the color with which plots will be plotted (this is dependent\n",
        "  # on the bullet color and was manually selected)\n",
        "  if lines == ['1', '2', '3']:\n",
        "    fig.suptitle('IRT 7 Av Line (1) (2) (3) Realtime Data', size=40, y=1.001,weight='bold')\n",
        "    linColor = 'red'\n",
        "  elif lines == ['4', '5', '6', '6X']:\n",
        "    fig.suptitle('IRT Lexington Av Line (4) (5) (6) (X) Realtime Data', size=40, y=1.001,weight='bold')\n",
        "    linColor = 'green'\n",
        "  elif lines == ['7', '7X']:\n",
        "    fig.suptitle('IRT Flushing Line (7) (X) Realtime Data', size=40, y=1.001,weight='bold')\n",
        "    linColor = 'mediumorchid'\n",
        "  elif lines == ['A', 'C', 'E']:\n",
        "    fig.suptitle('IND 8 Av Line (A) (C) (E) Realtime Data', size=40, y=1.001, weight='bold')\n",
        "    linColor = 'darkblue'\n",
        "  elif lines == ['B', 'D', 'F', 'M']:\n",
        "    fig.suptitle('IND 6 Av Line (                        ) Realtime Data', size=40, y=1.001, weight='bold')\n",
        "    linColor = 'darkorange'\n",
        "  elif lines == ['L']:\n",
        "    fig.suptitle('BMT Canarsie Line (L) Realtime Data', size=40, y=1.001, weight='bold')\n",
        "    linColor = 'darkgrey'\n",
        "  elif lines == ['G']:\n",
        "    fig.suptitle('IND Crosstown Line (G) Realtime Data', size=40, y=1.001, weight='bold')\n",
        "    linColor = 'limegreen'\n",
        "  elif lines == ['J']:\n",
        "    fig.suptitle('BMT Nassau Line ( J) (Z) Realtime Data', size=40, y=1.001, weight='bold')\n",
        "    linColor = 'brown'\n",
        "  elif lines == ['N', 'Q', 'R', 'W']:\n",
        "    fig.suptitle('BMT Broadway Line (                   ) Realtime Data', size=40, y=1.001, weight='bold')\n",
        "    linColor = 'gold'\n",
        "\n",
        "  # Iterate through each line, direction, time triplet\n",
        "  for i, line in enumerate(lines):\n",
        "    for k, dir in enumerate(directions):\n",
        "      for j, time in enumerate(times):\n",
        "\n",
        "          # Extract several pieces of information from partOne function\n",
        "          stopDict, stopNames, timeList, time1, time2, filteredSecondsDf = partOne(line, dir, time)\n",
        "\n",
        "          # For each train trip in the filteredSecondsDf, extract the station times and the stop vals\n",
        "          for trip in list(filteredSecondsDf.index):\n",
        "            tripDf = filteredSecondsDf.loc[trip]\n",
        "            stationTimes = tripDf['arrival_time_sec']\n",
        "            stopVal = tripDf['stop_val']\n",
        "\n",
        "            # If the train is express variant of 6 or 7, plot it on the row before, else print it\n",
        "            # as normal\n",
        "            if dir == 'N' and 'X' in line:\n",
        "              axs[i*2+j-1,k].plot(stationTimes, stopVal, color = linColor)\n",
        "            else:\n",
        "              axs[i*2+j,k].plot(stationTimes, stopVal, color = linColor)\n",
        "\n",
        "          # Train labels; if train is 7 or 7X, 7X runs \"South\" in the morning so this will be\n",
        "          # included and the south will be changed to west, which more accurately reflects how the\n",
        "          # way the 7 train travels. The J is also trained to westbound. Else the train is just listed as\n",
        "          # southbound. Final destination of train extracted from stopNames dictionary keys\n",
        "          if dir == 'S':\n",
        "            if time == 'morning':\n",
        "              if line == '7' or line == '7X':\n",
        "                axs[i*2+j, k].set_title(f'AM Rush Hour Westbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "              elif line == 'J':\n",
        "                axs[i*2+j, k].set_title(f'AM Rush Hour Westbound ( J) and (Z) Trains to {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              else:\n",
        "                axs[i*2+j, k].set_title(f'AM Rush Hour Southbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "\n",
        "            # Simiar procedure for westbound evening\n",
        "            else:\n",
        "              if 'X' in line:\n",
        "                pass\n",
        "              else:\n",
        "                if line == '7':\n",
        "                  axs[i*2+j, k].set_title(f'PM Rush Hour Westbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "                elif line == 'J':\n",
        "                  axs[i*2+j, k].set_title(f'AM Rush Hour Westbound (J) Train to {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "                else:\n",
        "                  axs[i*2+j, k].set_title(f'PM Rush Hour Southbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "\n",
        "          # Similar procedure for eastbound morning\n",
        "          else:\n",
        "            if time == 'morning':\n",
        "              if 'X' in line:\n",
        "                pass\n",
        "              else:\n",
        "                if line == '7':\n",
        "                  axs[i*2+j, k].set_title(f'AM Rush Hour Eastbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "                elif line == 'J':\n",
        "                  axs[i*2+j, k].set_title(f'AM Rush Hour Eastbound (J) Train to {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "                else:\n",
        "                  axs[i*2+j, k].set_title(f'AM Rush Hour Northbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "\n",
        "            # Similar procedure for eastbound evening\n",
        "            else:\n",
        "              if 'X' in line:\n",
        "                if line == '7X':\n",
        "                  axs[i*2+j-1, k].set_title(f'PM Rush Hour Eastbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "                else:\n",
        "                  axs[i*2+j-1, k].set_title(f'PM Rush Hour Northbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "              else:\n",
        "                if line == '7':\n",
        "                  axs[i*2+j, k].set_title(f'PM Rush Hour Eastbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "                elif line == 'J':\n",
        "                  axs[i*2+j, k].set_title(f'AM Rush Hour Eastbound (J) and (Z) Trains to {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "                else:\n",
        "                  axs[i*2+j, k].set_title(f'PM Rush Hour Northbound ({line}) Train to {list(stopNames.values())[-1]}', size=20)\n",
        "\n",
        "          # If X lines are being plotted, shift rows by 1 (only two express trains as they are\n",
        "          # peak direction express compared to four permutations). Add time and axis station labels\n",
        "          # and plot using stopDict.values() and stopNames.values()\n",
        "          if 'X' in line and dir == 'N' and time == 'evening':\n",
        "            axs[i*2+j-1, k].grid()\n",
        "            axs[i*2+j-1, k].set_xlabel('Time')\n",
        "            axs[i*2+j-1, k].set_xticks(np.arange(time1, time2+1, 900), timeList)\n",
        "            axs[i*2+j-1, k].set_ylabel('Stations')\n",
        "            axs[i*2+j-1, k].set_yticks(list(stopDict.values()), stopNames.values())\n",
        "\n",
        "            # Invert the y axis if it is northbound so that the lines in the graph travel differently\n",
        "            if k == 0:\n",
        "              axs[i*2+j-1,k].invert_yaxis()\n",
        "            axs[i*2+j-1,k].margins(x=0)\n",
        "            axs[i*2+j-1,k].margins(y=0)\n",
        "\n",
        "          # These are not possibilities as they are not peak direction so they are not plotted\n",
        "          elif 'X' in line and dir == 'N' and time == 'morning':\n",
        "            pass\n",
        "          elif 'X' in line and dir == 'S' and time == 'evening':\n",
        "            pass\n",
        "\n",
        "          # Perform similar procedure for X in line and direction is S and time is morning\n",
        "          else:\n",
        "            axs[i*2+j, k].grid()\n",
        "            axs[i*2+j, k].set_xlabel('Time')\n",
        "            axs[i*2+j, k].set_xticks(np.arange(time1, time2+1, 900), timeList)\n",
        "            axs[i*2+j, k].set_ylabel('Stations')\n",
        "            axs[i*2+j, k].set_yticks(list(stopDict.values()), stopNames.values())\n",
        "            if k == 0:\n",
        "              axs[i*2+j,k].invert_yaxis()\n",
        "            axs[i*2+j,k].margins(x=0)\n",
        "            axs[i*2+j,k].margins(y=0)\n",
        "\n",
        "  # For each set of lines, add their image to the title of the graph using readBullet\n",
        "  # and positioning (guess and check)\n",
        "  if lines == ['1', '2', '3']:\n",
        "    imagebox = OffsetImage(readBullet('1'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.455, .996), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('2'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.49065, .996), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('3'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5269, .996), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  # Do same for Lex Av lines\n",
        "  elif lines == ['4', '5', '6', '6X']:\n",
        "    imagebox = OffsetImage(readBullet('4'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.48245, .996), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('5'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5196, .996), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('6'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.55495, .996), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('6X'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5912, .996), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  # Do same for Flushing lines\n",
        "  elif lines == ['7', '7X']:\n",
        "    imagebox = OffsetImage(readBullet('7'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.49445, .99), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('7X'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5307, .99), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  # Do same for 8 Av lines\n",
        "  elif lines == ['A', 'C', 'E']:\n",
        "    imagebox = OffsetImage(readBullet('A'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.458, .995), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('C'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.49365, .995), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('E'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5299, .995), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  # Do same for 6 Av lines\n",
        "  elif lines == ['B', 'D', 'F', 'M']:\n",
        "    imagebox = OffsetImage(readBullet('B'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.42145, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('D'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.4586, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('F'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.49395, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('FX'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5302, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('M'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.56645, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  # Do same for G, L, and J trains\n",
        "  elif lines == ['G']:\n",
        "    imagebox = OffsetImage(readBullet('G'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5262, .985), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  elif lines == ['L']:\n",
        "    imagebox = OffsetImage(readBullet('L'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5212, .985), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  elif lines == ['J']:\n",
        "    imagebox = OffsetImage(readBullet('J'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.49495, .985), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('Z'), zoom=0.05)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5312, .985), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  # Do same for Broadway lines\n",
        "  elif lines == ['N', 'Q', 'R', 'W']:\n",
        "    imagebox = OffsetImage(readBullet('N'), zoom=0.0725)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.47245, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('Q'), zoom=0.0725)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5096, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('R'), zoom=0.0725)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.54495, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "    imagebox = OffsetImage(readBullet('W'), zoom=0.0725)  # Adjust zoom as needed for size\n",
        "    ab = AnnotationBbox(imagebox, (0.5812, .997), xycoords='figure fraction', frameon=False, pad=0, zorder=200)  # pad=0 to remove padding\n",
        "    fig.add_artist(ab)\n",
        "\n",
        "  # Use tight layout and plot the graphs\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "def distributionFinder(line, direction, rushHourType):\n",
        "  \"\"\"Finds distribution of intervals between trains for a line given time\n",
        "  and direction. Returns distribution as a numpy array.\"\"\"\n",
        "\n",
        "  # Initializes global variables\n",
        "  global df\n",
        "  global stopsDf\n",
        "\n",
        "  # Runs noExpressDifferentiatedQuery to get list of trips associated with\n",
        "  # a specific line and direction\n",
        "  subwayDf = noExpressDifferentiatedQuery(df, line, direction)\n",
        "\n",
        "  # Add seconds to stop times which are currently in HH:MM:SS\n",
        "  timeDf = addSeconds(subwayDf, ['arrival_time', 'departure_time'])\n",
        "\n",
        "  # Set rush hour times as defined by MTA in seconds\n",
        "  if rushHourType == 'evening':\n",
        "    time1 = 55800\n",
        "    time2 = 72000\n",
        "  else:\n",
        "    time1 = 23400\n",
        "    time2 = 34200\n",
        "\n",
        "  # Run secondsDf\n",
        "  secondsDf = subwayTimeQuery(timeDf, 'arrival_time_sec', 'departure_time_sec', time1, time2)\n",
        "\n",
        "  # Extract stops and get stop names using stopIDtoName and return stopDict,\n",
        "  # filteredSecondsDf, and stopNames\n",
        "  filteredSecondsDf, stopDict = stopExtractor(secondsDf, line, direction)\n",
        "  stopNames = stopIDtoName(stopsDf, list(stopDict.keys()))\n",
        "  return stopDict, filteredSecondsDf, stopNames\n",
        "\n",
        "def noExpressDifferentiatedQuery(df, line, direction):\n",
        "  \"\"\"Takes in dataframe with realtime subway data, string representing subway line,\n",
        "  and string representing direction. Returns dataframe with rows that\n",
        "  correspond to weekdays, the line specified by the user, and the direction\n",
        "  specified by the user. Does not differentiate by express vs. local variants for\n",
        "  6, 7, and F trains\"\"\"\n",
        "\n",
        "  # Uses similar validation to subwayQuery function\n",
        "  if line == '7' or line == 'E' or line == 'F' or line == 'M' or line == 'R' or line == 'J':\n",
        "    joinedString = f\"{line}..{direction}\"\n",
        "    filteredDf = df.query(f'trip_id.str.contains(\"L0S1\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # W train dealt with separately because it is associated with the N in the data\n",
        "  elif line == 'W':\n",
        "\n",
        "    # Uses code to extract W trains running either northbound or southbound based on direction\n",
        "    # specified when function was called\n",
        "    if direction == 'N':\n",
        "      joinedString = \"N..N72\"\n",
        "    else:\n",
        "      joinedString = \"N..S72\"\n",
        "    filteredDf = df.query(f'trip_id.str.contains(\"Weekday\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # N train\n",
        "  elif line == 'N':\n",
        "\n",
        "    # Removes W trains\n",
        "    joinedString1 = f\"N..N72\"\n",
        "    joinedString2 = f\"N..S72\"\n",
        "    filteredDf1 = df[~df.index.str.contains(f\"_{joinedString1}\")]\n",
        "    filteredDf2 = filteredDf1[~filteredDf1.index.str.contains(f\"_{joinedString2}\")]\n",
        "\n",
        "    # Only preserves rows associated with N train\n",
        "    joinedString = f\"{line}..{direction}\"\n",
        "    filteredDf = filteredDf2.query(f'trip_id.str.contains(\"Weekday\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "\n",
        "  # If normal train than filtering is done normally\n",
        "  else:\n",
        "    joinedString = f\"{line}..{direction}\"\n",
        "    filteredDf = df.query(f'trip_id.str.contains(\"Weekday\") and trip_id.str.contains(\"_{joinedString}\")', engine='python')\n",
        "  return filteredDf\n",
        "\n",
        "def pairwiseDifferences(df, columnName):\n",
        "  \"\"\"Given dataframe and a specified column name, returns numpy array of all pairwise\n",
        "  differences in that column.\"\"\"\n",
        "\n",
        "  # A column is taken and converted into a numpy array and sorted in ascending order\n",
        "  column = df[columnName]\n",
        "  colArray = np.array(column)\n",
        "  sortedColArray = np.sort(colArray)\n",
        "\n",
        "  # The pairwise differences are taken\n",
        "  pairwiseDiff = np.abs(np.diff(sortedColArray))\n",
        "\n",
        "  # Throwing out excessive times created by  4 train skipping 138 St\n",
        "  pairwiseDiff = pairwiseDiff[pairwiseDiff < 7000]\n",
        "\n",
        "  # Return pairwiseDiff\n",
        "  return pairwiseDiff\n",
        "\n",
        "def lineDistribution(line, direction, rushHourType):\n",
        "  \"\"\"Given a dataframe, a specified line, and time of rush hour (morning or night),\n",
        "  generates array with all times in between trains for all stations in that line.\"\"\"\n",
        "\n",
        "  # Runs distributionFinder to get stopDict, filteredSecondsDf, and stopNames\n",
        "  stopDict, filteredSecondsDf, stopNames = distributionFinder(line, direction, rushHourType)\n",
        "\n",
        "  # Creates empty list that will contain distribution of times in between trains for all stations\n",
        "  # in that line\n",
        "  dist = []\n",
        "\n",
        "  # For each stop as listed in stopDict.keys()\n",
        "  for stop in stopDict.keys():\n",
        "\n",
        "    # Stops included in the graph that are not part of the normal service pattern are skipped\n",
        "    if line == 'E' and stop == 'F05'+direction:\n",
        "      continue\n",
        "    if line == 'E' and stop == 'F07'+direction:\n",
        "      continue\n",
        "    if line == 'A' and stop == 'A14'+direction:\n",
        "      continue\n",
        "    if line == 'D' and stop == 'R30'+direction:\n",
        "      continue\n",
        "    if (line == 'D' or line == 'N') and 'R' in stop and (32 <= int(stop[1:3]) and 35 >= int(stop[1:3])):\n",
        "      continue\n",
        "\n",
        "    # N train going local sometimes is dealt with here\n",
        "    if line  == 'N' and (stop[0:3] == 'R40' or stop[0:3] == 'R39' or stop[0:3] == 'R32'\n",
        "      or stop[0:3] == 'R33' or stop[0:3] == 'R34' or stop[0:3] == 'R35' or stop[0:3] == 'R30'\n",
        "      or stop[0:3] == 'R29' or stop[0:3] == 'R28' or stop[0:3] == 'R27' or stop[0:3] == 'R26'\n",
        "      or stop[0:3] == 'R25' or stop[0:3] == 'R24' or stop[0:3] == 'R23' or stop[0:3] == 'R22'\n",
        "      or stop[0:3] == 'R21' or stop[0:3] == 'R19' or stop[0:3] == 'R18'):\n",
        "      continue\n",
        "\n",
        "    # Station arrivals is taken from filteredSecondsDf and querying it for a specific stop\n",
        "    stationArrivals = filteredSecondsDf.query(f'stop_id.str.contains(\"{stop}\")')\n",
        "\n",
        "    # Pairwise differences are found for stationArrivals\n",
        "    pairDiff = pairwiseDifferences(stationArrivals, 'arrival_time_sec')\n",
        "\n",
        "    # The distributions are hstacked (concatenation)\n",
        "    dist = np.hstack((dist, pairDiff))\n",
        "\n",
        "  # Returning distribution and stopNames\n",
        "  return dist, stopNames\n",
        "\n",
        "def trainIntervals(system):\n",
        "  \"\"\"Based on a given system (IRT or IND), plots all of the histograms representing\n",
        "  distributions for time in between trains based on time of day and type of rush hour.\"\"\"\n",
        "\n",
        "  # Sets title and axes to bold, initializes possible directions and times\n",
        "  plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "  plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "  plt.style.use('default')\n",
        "  directions = ['S', 'N']\n",
        "  times = ['morning', 'evening']\n",
        "\n",
        "  # Associates each system with their respective lines\n",
        "  if system == 'IRT':\n",
        "    lines = ['1', '2', '3', '4', '5', '6', '7']\n",
        "  else:\n",
        "    lines = ['A', 'C', 'E', 'B', 'D', 'F', 'M', 'G', 'L', 'J', 'N', 'Q',\n",
        "             'R', 'W']\n",
        "\n",
        "  # Creates plot\n",
        "  fig, axs = plt.subplots(len(lines), len(directions)+len(times), figsize=(30, 75*len(lines)/14))\n",
        "\n",
        "  # Titles based on which system\n",
        "  if system == 'IRT':\n",
        "    fig.suptitle('IRT Train Interval Data', size=40, y=1.001,weight='bold')\n",
        "  else:\n",
        "    fig.suptitle('IND and BMT Train Interval Data', size=40, y=1.001, weight='bold')\n",
        "\n",
        "  # Iterates over line, direction, and time in three nested for\n",
        "  for i, line in enumerate(lines):\n",
        "    for k, dir in enumerate(directions):\n",
        "      for j, time in enumerate(times):\n",
        "\n",
        "          # Get the distribution and stopNames from lineDistribution specified for the line, direction, and time\n",
        "          dist, stopNames = lineDistribution(line, dir, time)\n",
        "\n",
        "          # Organize titles based on direction and time of day\n",
        "          if dir == 'S':\n",
        "\n",
        "            # Morning and southbound\n",
        "            if time == 'morning':\n",
        "\n",
        "              # Set 7 and J trains to westbound instead of southbound to better reflect their directionality\n",
        "              if line == '7':\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Westbound (7) and (7X) Trains\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              elif line == 'J':\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Westbound (J) and (Z) Trains\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              elif line == '6':\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Southbound (6) and (6X) Trains\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              else:\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Southbound ({line}) Train\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "\n",
        "            # Do the same for evening and southbound\n",
        "            else:\n",
        "              if line == '7':\n",
        "                axs[i, j+2*k].set_title(f'PM Rush Hour Westbound ({line}) Train\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              elif line == 'J':\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Westbound (J) Train\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              else:\n",
        "                axs[i, j+2*k].set_title(f'PM Rush Hour Southbound ({line}) Train\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "\n",
        "          # Northbound\n",
        "          else:\n",
        "\n",
        "            # Morning and northbound\n",
        "            if time == 'morning':\n",
        "              if line == '7':\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Eastbound ({line}) Train\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              elif line == 'J':\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Eastbound (J) Train\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              else:\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Northbound ({line}) Train\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "\n",
        "            # Mornign and southbound\n",
        "            else:\n",
        "              if line == '7':\n",
        "                  axs[i, j+2*k].set_title(f'PM Rush Hour Eastbound (7) and (7X) Trains\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              elif line == 'J':\n",
        "                axs[i, j+2*k].set_title(f'AM Rush Hour Eastbound (J) and (Z) Trains\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              elif line == '6':\n",
        "                axs[i, j+2*k].set_title(f'PM Rush Hour Northbound (6) and (6X) Trains\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "              else:\n",
        "                axs[i, j+2*k].set_title(f'PM Rush Hour Northbound ({line}) Train\\nto {list(stopNames.values())[-1]}', size=20, wrap=True)\n",
        "\n",
        "          # Set line color based on the color of the train line\n",
        "          if line in ['1', '2', '3']:\n",
        "            linColor = 'red'\n",
        "          elif line in ['4', '5', '6']:\n",
        "            linColor = 'green'\n",
        "          elif line == '7':\n",
        "            linColor = 'mediumorchid'\n",
        "          elif line in ['A', 'C', 'E']:\n",
        "            linColor = 'darkblue'\n",
        "          elif line in ['B', 'D', 'F', 'M']:\n",
        "            linColor = 'darkorange'\n",
        "          elif line in ['N', 'Q', 'R', 'W']:\n",
        "            linColor = 'gold'\n",
        "          elif line == 'L':\n",
        "            linColor = 'darkgray'\n",
        "          elif line == 'J':\n",
        "            linColor = 'brown'\n",
        "          elif line == 'G':\n",
        "            linColor = 'limegreen'\n",
        "\n",
        "          # Create axes, setting each bin width to 33.3\n",
        "          axs[i, j+2*k].hist(dist, bins=np.linspace(0,1100,34,endpoint=True), color=linColor)  # bins determine the number of bins in the histogram\n",
        "          axs[i, j+2*k].set_xlabel('Times Between Trains (s)')\n",
        "          axs[i, j+2*k].set_ylabel('Frequency')\n",
        "          axs[i, j+2*k].grid()\n",
        "          axs[i, j+2*k].grid(True)\n",
        "          axs[i, j+2*k].margins(x=0)\n",
        "          axs[i, j+2*k].margins(y=0)\n",
        "          axs[i, j+2*k].set_xlim([0,1100])\n",
        "          axs[i, j+2*k].set_ylim([0,900])\n",
        "\n",
        "\n",
        "  # Use tight layout and plot the plot\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  return\n",
        "\n",
        "def shapirowilk(dataval):\n",
        "  \"\"\"Takes in list or 1D array of data values and returns p statistic from test.\"\"\"\n",
        "  stat, p = shapiro(dataval)\n",
        "  return p\n",
        "\n",
        "def anovatest(distDict):\n",
        "  \"\"\"Takes in dictionary associating lines with their distributions.\n",
        "  Perform ANOVA test on these distributions and returns associated p-val\"\"\"\n",
        "\n",
        "  # Run ANOVA test and return p-val\n",
        "  stat, p = f_oneway(*list(distDict.values()))\n",
        "  return p\n",
        "\n",
        "def mannwhitneypairwise(type1, type2):\n",
        "  \"\"\"Takes in two lists/1D arrays (type1 and type2) and returns p val.\"\"\"\n",
        "  stat, p = mannwhitneyu(type1, type2)\n",
        "  return stat, p\n",
        "\n",
        "def twosamplet(type1, type2):\n",
        "  \"\"\"Takes in two lists or arrays of data and returns p val.\"\"\"\n",
        "  stat, p = ttest_ind(type1, type2)\n",
        "  return stat, p\n",
        "\n",
        "def trainComparison(lines, direction, rushHourType):\n",
        "  \"\"\"Takes in a set of lines, a common direction, and rushHourType.\n",
        "  Performs ANOVA test and returns p-value. Runs Shapiro Wilk Normality test on all data.\n",
        "  and returns dataframe of p-values and whether all\n",
        "  data is normal or not as a boolean. If all data are normal, performs pairwise\n",
        "  t-tests on all data. If all data are not normal, performs pairwise Mann Whitney\n",
        "  U tests on all data. Returns matrix of pairwise p-values.\"\"\"\n",
        "\n",
        "  # Set empty dictionary to distributions and empty dictionary with shapiroWilk data values\n",
        "  distDict = {}\n",
        "  shapWilkDict = {}\n",
        "  normal = True\n",
        "\n",
        "  # For each line, find distribution and run Shapiro Wilk test. Associate that p value with\n",
        "  # the line in the shapWilkDict\n",
        "  for line in lines:\n",
        "    dist, stopNames = lineDistribution(line, direction, rushHourType)\n",
        "    distDict[line] = dist\n",
        "    shapWilkDict[line] = shapirowilk(distDict[line])\n",
        "\n",
        "  # If the p val of any of the lines is less than 0.05, we can reject the null hypothesis that\n",
        "  # the dataset is normal and conclude it is not normal\n",
        "  for line in lines:\n",
        "    if shapWilkDict[line] < 0.05:\n",
        "      normal = False\n",
        "      break\n",
        "\n",
        "  # Perform ANOVA test\n",
        "  anovapval = anovatest(distDict)\n",
        "\n",
        "  # Initialize an empty DataFrame with groups as rows and columns\n",
        "  columns = lines.copy()\n",
        "  index = lines.copy()\n",
        "  statDf = pd.DataFrame(np.zeros((len(lines), len(lines)), dtype=float))\n",
        "  statDf.columns = columns\n",
        "  statDf.index = index\n",
        "\n",
        "  # Perform pairwise t-tests and populate the DataFrame\n",
        "  for i in range(len(lines)):\n",
        "      for j in range(len(lines)):\n",
        "          if i != j:\n",
        "            if normal == True:\n",
        "              stat, p = twosamplet(distDict[lines[i]], distDict[lines[j]])\n",
        "              statDf.iloc[i, j] = float(p)\n",
        "            else:\n",
        "              stat, p = mannwhitneyu(distDict[lines[i]], distDict[lines[j]])\n",
        "              statDf.iloc[i, j] = float(p)\n",
        "\n",
        "      # Set t tests between the same train lines in the dataframe as 1\n",
        "      statDf.iloc[i,i] = float(1)\n",
        "\n",
        "  # Return the shapWilkDict, anovapval, the normality of the distribution as a\n",
        "  # Boolean, and the statDf dictionary\n",
        "  return shapWilkDict, anovapval, normal, statDf\n",
        "\n",
        "def makeHeatmap(statDf, normal, direction, rushHourType):\n",
        "    \"\"\"Using the statDf that contains pvals from pairwise t-tests/MWU tests, creates a heatmap.\"\"\"\n",
        "\n",
        "    # Replace 0 values with NaN to handle logarithmic transformation\n",
        "    statDf[statDf == 0] = np.nan\n",
        "\n",
        "    # Logarithmically scale heatmap using log base 10\n",
        "    logStatDf = np.log10(statDf)\n",
        "\n",
        "    # Define a custom colormap that maps NaN to white and other values to a red-blue gradient\n",
        "    cmap_colors = matplotlib.colormaps['spring']\n",
        "    cmap_colors.set_bad('black')  # Set color for NaN values to white\n",
        "\n",
        "    # Set figure size to make the plot square\n",
        "    plt.figure(figsize=(20, 20))  # Adjust the size as needed\n",
        "\n",
        "    # Plot heatmap with custom colormap and normalization\n",
        "    plt.imshow(logStatDf, cmap=cmap_colors, interpolation='nearest', aspect='auto')\n",
        "\n",
        "    # Set tick labels for x-axis (columns) and y-axis (indices) based on DataFrame\n",
        "    plt.xticks(ticks=np.arange(len(statDf.columns)), labels=statDf.columns, ha='right')\n",
        "    plt.yticks(ticks=np.arange(len(statDf.index)), labels=statDf.index)\n",
        "\n",
        "    # Set direction label based on input\n",
        "    dir_label = 'Northbound' if direction == 'N' else 'Southbound'\n",
        "\n",
        "    # Set time label based on rush hour type\n",
        "    time_label = 'AM' if rushHourType == 'morning' else 'PM'\n",
        "\n",
        "    # Annotate non-NaN values with their corresponding value\n",
        "    for i in range(logStatDf.shape[0]):\n",
        "        for j in range(logStatDf.shape[1]):\n",
        "            value = logStatDf.iloc[i, j]  # Use iloc for indexing\n",
        "            if not np.isnan(value):\n",
        "                plt.text(j, i, f'{value:.2f}', ha='center', va='center', color='black', weight='bold', fontsize=9)\n",
        "\n",
        "    # Set title based on test type\n",
        "    test_type = 'Pairwise t-Tests' if normal else 'Pairwise Mann-Whitney U Tests'\n",
        "    plt.title(f'Logarithmic Heat Map (Base 10) of {test_type}\\nfor {time_label} {dir_label} Trains', fontsize=25)\n",
        "\n",
        "    # Show colorbar to indicate scale\n",
        "    plt.colorbar(label='Logarithmic Value')\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "\n",
        "def combineDistributions(lines):\n",
        "  \"\"\"Combines the four distributions created for a line (N and morning, N and\n",
        "  evening, S and morning, S and evening) into one distribution for comparison\n",
        "  between lines.\"\"\"\n",
        "\n",
        "  # Create empty dictionary\n",
        "  distDict = {}\n",
        "\n",
        "  # Iterates over each line, runs lineDistribution for every combination of directions\n",
        "  # and times, extracts the first element in what is returned (the array with the\n",
        "  # distributions).\n",
        "  for line in lines:\n",
        "    dist1 = lineDistribution(line, 'N', 'morning')[0]\n",
        "    dist2 = lineDistribution(line, 'N', 'evening')[0]\n",
        "    dist3 = lineDistribution(line, 'S', 'morning')[0]\n",
        "    dist4 = lineDistribution(line, 'S', 'evening')[0]\n",
        "\n",
        "    # Assigns the concatenated distribution to the line in the distDict\n",
        "    distDict[line] = np.hstack((dist1, dist2, dist3, dist4))\n",
        "\n",
        "  # Return distDict\n",
        "  return distDict\n",
        "\n",
        "def boxAndWhisker(lines):\n",
        "    \"\"\" Creates a box and whisker plot for each line, highlighting 5 num summary.\n",
        "    Outliers excluded. Boxplots are ordered from lowest median to highest median\n",
        "    in order to get a picture of what trains come most frequently and what trains\n",
        "    the least.\"\"\"\n",
        "\n",
        "    # Run combineDistributions to get a dictionary\n",
        "    distDict = combineDistributions(lines)\n",
        "    medians = {key: np.median(value) for key, value in distDict.items()}\n",
        "    sortedLines = sorted(medians, key=medians.get)\n",
        "\n",
        "    # Create a figure and axis for the plot\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    categoryColors = {\n",
        "        '1': '#EE352E',   # red\n",
        "        '2': '#EE352E',   # red\n",
        "        '3': '#EE352E',   # red\n",
        "        '4': '#00933C',   # green\n",
        "        '5': '#00933C',   # green\n",
        "        '6': '#00933C',   # green\n",
        "        '7': '#B933AD',   # purple\n",
        "        'A': '#0039A6',   # blue\n",
        "        'C': '#0039A6',   # blue\n",
        "        'E': '#0039A6',   # blue\n",
        "        'B': '#FF6319',   # orange\n",
        "        'D': '#FF6319',   # orange\n",
        "        'F': '#FF6319',   # orange\n",
        "        'M': '#FF6319',   # orange\n",
        "        'G': '#6CBE45',   # lime green\n",
        "        'J': '#996633',   # brown\n",
        "        'Z': '#996633',   # brown\n",
        "        'L': '#A7A9AC',   # gray\n",
        "        'N': '#FCCC0A',   # yellow\n",
        "        'Q': '#FCCC0A',   # yellow\n",
        "        'R': '#FCCC0A',   # yellow\n",
        "        'W': '#FCCC0A',   # yellow\n",
        "    }\n",
        "\n",
        "    # Plot box and whisker plots for each category ordered by median\n",
        "    for i, line in enumerate(sortedLines):\n",
        "        data = distDict[line]\n",
        "        color = 'blue'  # Default color (replace with actual category_colors logic)\n",
        "\n",
        "        # Customize box color based on category (subway line)\n",
        "        if line in categoryColors:\n",
        "            color = categoryColors[line]\n",
        "\n",
        "        # Median color\n",
        "        medianColor = 'black'\n",
        "        if line not in ['N', 'Q', 'R', 'W', '7']:\n",
        "            medianColor = 'white'\n",
        "\n",
        "        # Plot box and whisker plot\n",
        "        bp = plt.boxplot(data, positions=[i+1], widths=0.6, patch_artist=True, medianprops=dict(color=medianColor), showfliers=False)\n",
        "\n",
        "        # Customize box colors\n",
        "        for box in bp['boxes']:\n",
        "            box.set_facecolor(color)\n",
        "\n",
        "    # Customize x-axis labels and other plot properties\n",
        "    newLines = ['J/Z' if i=='J' else i for i in sortedLines]\n",
        "    plt.xticks(range(1, len(sortedLines) + 1), newLines)\n",
        "    plt.xlabel('Lines', fontsize=12)\n",
        "    plt.ylabel('Time (s)', fontsize=12)\n",
        "    plt.title('Distribution of Time Between Trains for Different Lines', fontsize=14)\n",
        "\n",
        "    # Show grid and adjust layout\n",
        "    plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "def averageWaitTime(lines):\n",
        "  \"\"\"Given list of lines, returns their average wait times in a dataframe\n",
        "  as given by the Poisson distribution.\"\"\"\n",
        "\n",
        "  # Run combineDistributions to get a dictionary\n",
        "  distDict = combineDistributions(lines)\n",
        "\n",
        "  # Initialize new dictionary\n",
        "  waitTimeDict = {}\n",
        "\n",
        "  # Iterates over lines\n",
        "  for line in lines:\n",
        "\n",
        "    # Gets distribution from distDict\n",
        "    distribution = distDict[line]\n",
        "\n",
        "    # Finds mean interval in minutes\n",
        "    mean = np.mean(distribution)/60\n",
        "\n",
        "    # Adds to waitTimeDict\n",
        "    waitTimeDict[line] = mean\n",
        "\n",
        "  # Returns waitTimeDict\n",
        "  return waitTimeDict\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Creates list of all lines\n",
        "    lines = ['1','2','3','4','5','6','7',\n",
        "             'A','C','E','B','D','F','M',\n",
        "             'G','L','J','N','Q','R','W']\n",
        "\n",
        "    # Create trainPlots for each of the trunk lines\n",
        "    trainPlot(['1','2','3'])\n",
        "    trainPlot(['4','5','6','6X'])\n",
        "    trainPlot(['7','7X'])\n",
        "    trainPlot(['A','C','E'])\n",
        "    trainPlot(['B','D','F','M'])\n",
        "    trainPlot(['G'])\n",
        "    trainPlot(['L'])\n",
        "    trainPlot(['J'])\n",
        "    trainPlot(['N','Q','R','W'])\n",
        "\n",
        "    # Plot train intervals for IRT trains and IND trains\n",
        "    trainIntervals('IRT')\n",
        "    trainIntervals('BMT')\n",
        "\n",
        "    # Create matrix with normality tests, anova pval, whether the\n",
        "    # distributions are normal, and pairwise t test/Mann-Whitney U matrix\n",
        "    shapWilkDict1, anovapval1, normal1, statDf1 = trainComparison(lines, 'N', 'morning')\n",
        "    shapWilkDict2, anovapval2, normal2, statDf2 = trainComparison(lines, 'N', 'evening')\n",
        "    shapWilkDict3, anovapval3, normal3, statDf3 = trainComparison(lines, 'S', 'morning')\n",
        "    shapWilkDict4, anovapval4, normal4, statDf4 = trainComparison(lines, 'S', 'evening')\n",
        "\n",
        "    # Print shap wilk dictionaries\n",
        "    print(f\"Shapiro-Wilk Test p values for each line's train interval distribution going northbound in morning rush hour: {shapWilkDict1}\")\n",
        "    print(f\"Shapiro-Wilk Test p values for each line's train interval distribution going northbound in evening rush hour: {shapWilkDict2}\")\n",
        "    print(f\"Shapiro-Wilk Test p values for each line's train interval distribution going southbound in morning rush hour: {shapWilkDict3}\")\n",
        "    print(f\"Shapiro-Wilk Test p values for each line's train interval distribution going southbound in evening rush hour: {shapWilkDict4}\")\n",
        "\n",
        "    # Print whether normal or not\n",
        "    print(f\"Based on the Shapiro-Wilk p values, we assume that it is {normal1} that all all the train interval distributions are normally distributed for all lines going northbound in morning rush hour.\")\n",
        "    print(f\"Based on the Shapiro-Wilk p values, we assume that it is {normal2} that all all the train interval distributions are normally distributed for all lines going northbound in evening rush hour.\")\n",
        "    print(f\"Based on the Shapiro-Wilk p values, we assume that it is {normal3} that all all the train interval distributions are normally distributed for all lines going southbound in morning rush hour.\")\n",
        "    print(f\"Based on the Shapiro-Wilk p values, we assume that it is {normal4} that all all the train interval distributions are normally distributed for all lines going southbound in evening rush hour.\")\n",
        "\n",
        "    # Print ANOVA p-val\n",
        "    print(f\"ANOVA Test p value for all lines going northbound in morning rush hour: {anovapval1}\")\n",
        "    print(f\"ANOVA Test p value for all lines going northbound in evening rush hour: {anovapval2}\")\n",
        "    print(f\"ANOVA Test p value for all lines going southbound in morning rush hour: {anovapval3}\")\n",
        "    print(f\"ANOVA Test p value for all lines going southbound in evening rush hour: {anovapval4}\")\n",
        "\n",
        "    # Make heatmaps\n",
        "    makeHeatmap(statDf1, normal1, 'N', 'morning')\n",
        "    makeHeatmap(statDf2, normal2, 'N', 'evening')\n",
        "    makeHeatmap(statDf3, normal3, 'S', 'morning')\n",
        "    makeHeatmap(statDf4, normal4, 'S', 'evening')\n",
        "\n",
        "    # Print average wait time\n",
        "    print(f\"Average wait time dictionary (in minutes): {averageWaitTime(lines)}\")\n",
        "\n",
        "    # Box and whisker plot of line intervals\n",
        "    boxAndWhisker(lines)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "# readData is not unit tested because it has been used in past homeworks\n",
        "# extract is not unit tested due as it has no outputs\n",
        "\n",
        "class TestSubwayLineQuery(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_subwayLineQuery_OutputType(self):\n",
        "    \"\"\"Test output type of subwayLineQuery function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "        'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3'],\n",
        "        'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29'],\n",
        "        'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11'],\n",
        "        'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1'],\n",
        "        'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21'],\n",
        "        'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17'],\n",
        "        'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7'],\n",
        "        'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6'],\n",
        "        'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21'],\n",
        "        'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2'],\n",
        "        'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20'],\n",
        "        'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40'],\n",
        "        'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2'],\n",
        "        'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6'],\n",
        "        'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19'],\n",
        "        'FA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4'],\n",
        "        'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12']\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence']\n",
        "\n",
        "    # Create list of lines and directions to test\n",
        "    linesToTest = ['1','6','6X','7','7X','N','W','F','R']\n",
        "    directions = ['N','S']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Iterate through all of them, checking if a dataframe is always returned\n",
        "    for line in linesToTest:\n",
        "      for dir in directions:\n",
        "        subwayDf = subwayLineQuery(importedDf, line, dir)\n",
        "        self.assertIsInstance(subwayDf, pd.DataFrame, \"Returned object is not a DataFrame\")\n",
        "\n",
        "  # Write function\n",
        "  def test_subwayLineQuery_OutputValue(self):\n",
        "    \"\"\"Test output value of subwayLineQuery function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "        'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3'],\n",
        "        'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29'],\n",
        "        'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11'],\n",
        "        'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1'],\n",
        "        'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21'],\n",
        "        'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17'],\n",
        "        'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7'],\n",
        "        'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6'],\n",
        "        'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21'],\n",
        "        'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2'],\n",
        "        'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20'],\n",
        "        'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40'],\n",
        "        'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2'],\n",
        "        'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6'],\n",
        "        'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19'],\n",
        "        'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4'],\n",
        "        'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12']\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence']\n",
        "\n",
        "    # Create list of lines and directions to test\n",
        "    linesToTest = ['1','6','6X','7','7X','N','W','F','R']\n",
        "    directions = ['N','S']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Iterate through all of them, checking if correct dataframe is always returned\n",
        "    for line in linesToTest:\n",
        "      for dir in directions:\n",
        "        subwayDf = subwayLineQuery(importedDf, line, dir)\n",
        "        if line == '6' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-6089-Weekday-00_067800_6..N01R\")')\n",
        "        elif line == '6' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-6089-Weekday-00_067000_6..S03R\")')\n",
        "        elif line == '6X' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-6089-Weekday-00_075000_6..N02R\")')\n",
        "        elif line == '6X' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-6089-Weekday-00_048500_6..S08R\")')\n",
        "        elif line == '7' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-7-1064-S02_038000_7..N97R\")')\n",
        "        elif line == '7' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-7-1064-S02_096800_7..S97R\")')\n",
        "        elif line == '7X' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-7-1064-S02_096850_7..N97X005\")')\n",
        "        elif line == '7X' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-7-1064-S02_038300_7..S98X001\")')\n",
        "        elif line == 'N' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"BFA23GEN-N098-Weekday-00_104150_N..N33R\")')\n",
        "        elif line == 'N' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"BFA23GEN-N098-Weekday-00_103600_N..S34R\")')\n",
        "        elif line == 'W' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"NaN\")')\n",
        "        elif line == 'W' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"BFA23GEN-N098-Weekday-00_103100_N..S72R\") or trip_id.str.contains(\"BFA23GEN-N098-Weekday-00_104000_N..S72R\")')\n",
        "        elif line == 'F' and dir == 'N':\n",
        "            # We just need a blank dataframe for this case\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"NaN\")')\n",
        "        elif line == 'F' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-F-1077-S02_113250_F..S53X011\")')\n",
        "        elif line == 'R' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-R-1093-S02_129650_R..N78R\")')\n",
        "        elif line == 'R' and dir == 'S':\n",
        "            # We just need a blank dataframe in this case\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"NaN\")')\n",
        "        elif line == '1' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-1092-Weekday-00_057850_1..N13R\")')\n",
        "        elif line == '1' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-1092-Weekday-00_057950_1..S03R\")')\n",
        "\n",
        "        # Run test for each case\n",
        "        self.assertTrue(actualDf.equals(subwayDf),\n",
        "                    \"subwayLineQuery does not return the expected value.\")\n",
        "\n",
        "class TestGetSec(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_getSec_OutputType(self):\n",
        "    \"\"\"Test output type of getSec function.\"\"\"\n",
        "\n",
        "    # Create times in the form of HH:MM:SS\n",
        "    time1 = '07:32:00'\n",
        "    time2 = '13:59:59'\n",
        "    time3 = '25:12:20'\n",
        "\n",
        "    # Create list of times\n",
        "    timeList = [time1, time2, time3]\n",
        "\n",
        "    # Test type\n",
        "    for time in timeList:\n",
        "      self.assertTrue(type(getSec(time)) == int,\n",
        "      \"getSec needs to return an integer.\")\n",
        "\n",
        "  # Write function\n",
        "  def test_getSec_OutputValue(self):\n",
        "    \"\"\"Test output value of getSec function.\"\"\"\n",
        "\n",
        "    # Create times in the form of HH:MM:SS\n",
        "    time1 = '07:32:00'\n",
        "    time2 = '13:59:59'\n",
        "    time3 = '25:12:20'\n",
        "\n",
        "    # Test value\n",
        "    self.assertTrue(getSec(time1) == 27120,\n",
        "                    \"getSec does not return the expected value.\")\n",
        "    self.assertTrue(getSec(time2) == 50399,\n",
        "                    \"getSec does not return the expected value.\")\n",
        "    self.assertTrue(getSec(time3) == 90740,\n",
        "                    \"getSec does not return the expected value.\")\n",
        "\n",
        "class TestAddSeconds(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_addSeconds_OutputType(self):\n",
        "    \"\"\"Test output type of addSeconds function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "        'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3'],\n",
        "        'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29'],\n",
        "        'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11'],\n",
        "        'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1'],\n",
        "        'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21'],\n",
        "        'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17'],\n",
        "        'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7'],\n",
        "        'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6'],\n",
        "        'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21'],\n",
        "        'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2'],\n",
        "        'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20'],\n",
        "        'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40'],\n",
        "        'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2'],\n",
        "        'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6'],\n",
        "        'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19'],\n",
        "        'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4'],\n",
        "        'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12']\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    timeDf = addSeconds(importedDf, ['arrival_time', 'departure_time'])\n",
        "    self.assertIsInstance(timeDf, pd.DataFrame, \"Returned object is not a DataFrame\")\n",
        "\n",
        "  # Write function\n",
        "  def test_addSeconds_OutputValue(self):\n",
        "    \"\"\"Test output value of addSeconds function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function.\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "        'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3'],\n",
        "        'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29'],\n",
        "        'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11'],\n",
        "        'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1'],\n",
        "        'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21'],\n",
        "        'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17'],\n",
        "        'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7'],\n",
        "        'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6'],\n",
        "        'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21'],\n",
        "        'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2'],\n",
        "        'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20'],\n",
        "        'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40'],\n",
        "        'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2'],\n",
        "        'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6'],\n",
        "        'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19'],\n",
        "        'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4'],\n",
        "        'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12']\n",
        "    }\n",
        "\n",
        "    # The time has already been converted to seconds manually\n",
        "    modifiedDict = {\n",
        "    'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3', 5340, 5340],\n",
        "    'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29', 37230, 37230],\n",
        "    'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11', 35670, 35670],\n",
        "    'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1', 45000, 45000],\n",
        "    'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21', 42600, 42600],\n",
        "    'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17', 41700, 41700],\n",
        "    'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7', 29700, 29820],\n",
        "    'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6', 23820, 23820],\n",
        "    'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21', 24720, 24720],\n",
        "    'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2', 58260, 58260],\n",
        "    'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20', 60060, 60060],\n",
        "    'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40', 72990, 73200],\n",
        "    'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2', 77910, 77910],\n",
        "    'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6', 62310, 62310],\n",
        "    'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19', 64530, 64530],\n",
        "    'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4', 62910, 62910],\n",
        "    'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12', 63570, 63570]\n",
        "    }\n",
        "\n",
        "\n",
        "    # Specify column names\n",
        "    oldColumns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence']\n",
        "    newColumns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence',  'arrival_time_sec', 'departure_time_sec']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = oldColumns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Do the same with the modified df\n",
        "    modifiedDf = pd.DataFrame(modifiedDict).T\n",
        "    modifiedDf.columns = newColumns\n",
        "    modifiedDf = modifiedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    timeDf = addSeconds(importedDf, ['arrival_time', 'departure_time'])\n",
        "\n",
        "    # Extract time in seconds columns\n",
        "    modifiedArrivalTimes = modifiedDf['arrival_time_sec'].astype(int)\n",
        "    modifiedDepartureTimes = modifiedDf['departure_time_sec'].astype(int)\n",
        "    timeArrivalTimes = timeDf['arrival_time_sec'].astype(int)\n",
        "    timeDepartureTimes = timeDf['departure_time_sec'].astype(int)\n",
        "\n",
        "    # Test if the columns are equal\n",
        "    self.assertTrue(modifiedArrivalTimes.equals(timeArrivalTimes),\n",
        "                    \"addSeconds does not return the expected value.\")\n",
        "    self.assertTrue(modifiedDepartureTimes.equals(timeDepartureTimes),\n",
        "                    \"addSeconds does not return the expected value.\")\n",
        "\n",
        "class TestSubwayTimeQuery(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_subwayTimeQuery_OutputType(self):\n",
        "    \"\"\"Test output type of subwayTimeQuery function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "    'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3', 5340, 5340],\n",
        "    'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29', 37230, 37230],\n",
        "    'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11', 35670, 35670],\n",
        "    'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1', 45000, 45000],\n",
        "    'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21', 42600, 42600],\n",
        "    'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17', 41700, 41700],\n",
        "    'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7', 29700, 29820],\n",
        "    'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6', 23820, 23820],\n",
        "    'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21', 24720, 24720],\n",
        "    'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2', 58260, 58260],\n",
        "    'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20', 60060, 60060],\n",
        "    'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40', 72990, 73200],\n",
        "    'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2', 77910, 77910],\n",
        "    'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6', 62310, 62310],\n",
        "    'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19', 64530, 64530],\n",
        "    'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4', 62910, 62910],\n",
        "    'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12', 63570, 63570]\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence', 'arrival_time_sec', 'departure_time_sec']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    timeDf1 = subwayTimeQuery(importedDf, 'arrival_time_sec', 'departure_time_sec', 30000, 60000)\n",
        "    self.assertIsInstance(timeDf1, pd.DataFrame, \"Returned object is not a DataFrame\")\n",
        "    timeDf2 = subwayTimeQuery(importedDf, 'arrival_time_sec', 'departure_time_sec', 60060, 64530)\n",
        "    self.assertIsInstance(timeDf2, pd.DataFrame, \"Returned object is not a DataFrame\")\n",
        "\n",
        "  # Write function\n",
        "  def test_subwayTimeQuery_OutputValue(self):\n",
        "    \"\"\"Test output value of subwayTimeQuery function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function.\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "    'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3', 5340, 5340],\n",
        "    'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29', 37230, 37230],\n",
        "    'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11', 35670, 35670],\n",
        "    'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1', 45000, 45000],\n",
        "    'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21', 42600, 42600],\n",
        "    'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17', 41700, 41700],\n",
        "    'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7', 29700, 29820],\n",
        "    'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6', 23820, 23820],\n",
        "    'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21', 24720, 24720],\n",
        "    'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2', 58260, 58260],\n",
        "    'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20', 60060, 60060],\n",
        "    'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40', 72990, 73200],\n",
        "    'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2', 77910, 77910],\n",
        "    'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6', 62310, 62310],\n",
        "    'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19', 64530, 64530],\n",
        "    'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4', 62910, 62910],\n",
        "    'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12', 63570, 63570]\n",
        "    }\n",
        "\n",
        "    # The time has been filtered manually for a certain range (30000 to 60000)\n",
        "    modifiedDict1 = {\n",
        "    'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29', 37230, 37230],\n",
        "    'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11', 35670, 35670],\n",
        "    'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1', 45000, 45000],\n",
        "    'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21', 42600, 42600],\n",
        "    'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17', 41700, 41700],\n",
        "    'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2', 58260, 58260],\n",
        "    }\n",
        "\n",
        "    # The time has been filtered manually again for a different range (60060 to 64530)\n",
        "    modifiedDict2 = {\n",
        "    'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20', 60060, 60060],\n",
        "    'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6', 62310, 62310],\n",
        "    'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4', 62910, 62910],\n",
        "    'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12', 63570, 63570]\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence',  'arrival_time_sec', 'departure_time_sec']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Do the same with the modified df 1 and 2\n",
        "    modifiedDf1 = pd.DataFrame(modifiedDict1).T\n",
        "    modifiedDf1.columns = columns\n",
        "    modifiedDf1 = modifiedDf1.rename_axis(index='trip_id')\n",
        "    modifiedDf2 = pd.DataFrame(modifiedDict2).T\n",
        "    modifiedDf2.columns = columns\n",
        "    modifiedDf2 = modifiedDf2.rename_axis(index='trip_id')\n",
        "\n",
        "    # Run function\n",
        "    timeQuery1 = subwayTimeQuery(importedDf, 'arrival_time_sec', 'departure_time_sec', 30000, 60000)\n",
        "    timeQuery2 = subwayTimeQuery(importedDf, 'arrival_time_sec', 'departure_time_sec', 60060, 64530)\n",
        "\n",
        "    # Extract time in seconds columns\n",
        "    timeQuery1Arrival = timeQuery1['arrival_time_sec'].astype(int)\n",
        "    timeQuery1Departure = timeQuery1['departure_time_sec'].astype(int)\n",
        "    timeQuery2Arrival = timeQuery2['arrival_time_sec'].astype(int)\n",
        "    timeQuery2Departure = timeQuery2['departure_time_sec'].astype(int)\n",
        "    modifiedDf1Arrival = modifiedDf1['arrival_time_sec'].astype(int)\n",
        "    modifiedDf1Departure = modifiedDf1['departure_time_sec'].astype(int)\n",
        "    modifiedDf2Arrival = modifiedDf2['arrival_time_sec'].astype(int)\n",
        "    modifiedDf2Departure = modifiedDf2['departure_time_sec'].astype(int)\n",
        "\n",
        "    # Test if the columns are equal\n",
        "    self.assertTrue(modifiedDf1Arrival.equals(timeQuery1Arrival),\n",
        "                    \"subwayTimeQuery does not return the expected value.\")\n",
        "    self.assertTrue(modifiedDf1Departure.equals(timeQuery1Departure),\n",
        "                    \"subwayTimeQuery does not return the expected value.\")\n",
        "    self.assertTrue(modifiedDf2Arrival.equals(timeQuery2Arrival),\n",
        "                    \"subwayTimeQuery does not return the expected value.\")\n",
        "    self.assertTrue(modifiedDf2Departure.equals(timeQuery2Departure),\n",
        "                    \"subwayTimeQuery does not return the expected value.\")\n",
        "\n",
        "class TestReadBullet(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_readBullet_OutputType(self):\n",
        "    \"\"\"Test output type of readBullet function.\"\"\"\n",
        "\n",
        "    # Read test bullets\n",
        "    testBulletBlack = readBullet('Black')\n",
        "    testBulletBlue = readBullet('Blue')\n",
        "\n",
        "    # Test type\n",
        "    self.assertTrue(type(testBulletBlack) == np.ndarray,\n",
        "      \"readBullet needs to return an ndarray.\")\n",
        "    self.assertTrue(type(testBulletBlue) == np.ndarray,\n",
        "      \"readBullet needs to return an ndarray.\")\n",
        "\n",
        "  # Write function\n",
        "  def test_readBullet_OutputValue(self):\n",
        "    \"\"\"Test output value of readBullet function.\"\"\"\n",
        "\n",
        "    # Read test bullets\n",
        "    testBulletBlack = readBullet('Black')\n",
        "    testBulletBlue = readBullet('Blue')\n",
        "\n",
        "    # Test value of black image (should be all 255 because returned image should be white)\n",
        "    self.assertTrue(np.all(testBulletBlack ==  np.array([255, 255, 255])),\n",
        "                    \"readBullet does not return the expected value.\")\n",
        "\n",
        "    # Test value of blue image (should be all [0,0,255] because returned image should be RGB)\n",
        "    self.assertTrue(np.all(testBulletBlue == np.array([0,0,255])),\n",
        "                    \"readBullet does not return the expected value.\")\n",
        "\n",
        "class TestNoExpressDifferentiatedQuery(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_noExpressDifferentiatedQuery_OutputType(self):\n",
        "    \"\"\"Test output type of noExpressDifferentiatedQuery function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "        'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3'],\n",
        "        'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29'],\n",
        "        'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11'],\n",
        "        'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1'],\n",
        "        'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21'],\n",
        "        'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17'],\n",
        "        'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7'],\n",
        "        'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6'],\n",
        "        'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21'],\n",
        "        'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2'],\n",
        "        'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20'],\n",
        "        'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40'],\n",
        "        'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2'],\n",
        "        'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6'],\n",
        "        'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19'],\n",
        "        'FA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4'],\n",
        "        'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12']\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence']\n",
        "\n",
        "    # Create list of lines and directions to test\n",
        "    linesToTest = ['1','6','7','N','W','F','R']\n",
        "    directions = ['N','S']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Iterate through all of them, checking if a dataframe is always returned\n",
        "    for line in linesToTest:\n",
        "      for dir in directions:\n",
        "        noExpressDf = noExpressDifferentiatedQuery(importedDf, line, dir)\n",
        "        self.assertIsInstance(noExpressDf, pd.DataFrame, \"Returned object is not a DataFrame\")\n",
        "\n",
        "  # Write function\n",
        "  def test_noExpressDifferentiatedQuery_OutputValue(self):\n",
        "    \"\"\"Test output value of noExpressDifferentiatedQuery function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "        'AFA23GEN-1038-Sunday-00_008600_1..S03R': ['104S', '01:29:00', '01:29:00', '3'],\n",
        "        'AFA23GEN-1092-Weekday-00_057850_1..N13R': ['112N', '10:20:30', '10:20:30', '29'],\n",
        "        'AFA23GEN-1092-Weekday-00_057950_1..S03R': ['113S', '09:54:30', '09:54:30', '11'],\n",
        "        'AFA23GEN-6089-Weekday-00_075000_6..N02R': ['640N', '12:30:00', '12:30:00', '1'],\n",
        "        'AFA23GEN-6089-Weekday-00_067800_6..N01R': ['619N', '11:50:00', '11:50:00', '21'],\n",
        "        'AFA23GEN-6089-Weekday-00_067000_6..S03R': ['625S', '11:35:00', '11:35:00', '17'],\n",
        "        'AFA23GEN-6089-Weekday-00_048500_6..S08R': ['608S', '08:15:00', '08:17:00', '7'],\n",
        "        'L0S1-7-1064-S02_038300_7..S98X001': ['712S', '06:37:00', '06:37:00', '6'],\n",
        "        'L0S1-7-1064-S02_038000_7..N97R': ['702N', '06:52:00', '06:52:00', '21'],\n",
        "        'L0S1-7-1064-S02_096850_7..N97X005': ['725N', '16:11:00', '16:11:00', '2'],\n",
        "        'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20'],\n",
        "        'L0S1-F-1077-S02_113250_F..S53X011': ['F35S', '20:16:30', '20:20:00', '40'],\n",
        "        'L0S1-R-1093-S02_129650_R..N78R': ['R44N', '21:38:30', '21:38:30', '2'],\n",
        "        'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6'],\n",
        "        'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19'],\n",
        "        'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4'],\n",
        "        'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12']\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence']\n",
        "\n",
        "    # Create list of lines and directions to test\n",
        "    linesToTest = ['1','6','7','N','W','F','R']\n",
        "    directions = ['N','S']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Iterate through all of them, checking if correct dataframe is always returned\n",
        "    for line in linesToTest:\n",
        "      for dir in directions:\n",
        "        noExpressDf = noExpressDifferentiatedQuery(importedDf, line, dir)\n",
        "        if line == '6' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-6089-Weekday-00_067800_6..N01R\") or trip_id.str.contains(\"AFA23GEN-6089-Weekday-00_075000_6..N02R\")')\n",
        "        elif line == '6' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-6089-Weekday-00_067000_6..S03R\") or trip_id.str.contains(\"AFA23GEN-6089-Weekday-00_048500_6..S08R\")')\n",
        "        elif line == '7' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-7-1064-S02_038000_7..N97R\") or trip_id.str.contains(\"L0S1-7-1064-S02_096850_7..N97X005\")')\n",
        "        elif line == '7' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-7-1064-S02_096800_7..S97R\") or trip_id.str.contains(\"L0S1-7-1064-S02_038300_7..S98X001\")')\n",
        "        elif line == 'N' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"BFA23GEN-N098-Weekday-00_104150_N..N33R\")')\n",
        "        elif line == 'N' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"BFA23GEN-N098-Weekday-00_103600_N..S34R\")')\n",
        "        elif line == 'W' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"NaN\")')\n",
        "        elif line == 'W' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"BFA23GEN-N098-Weekday-00_103100_N..S72R\") or trip_id.str.contains(\"BFA23GEN-N098-Weekday-00_104000_N..S72R\")')\n",
        "        elif line == 'F' and dir == 'N':\n",
        "            # We just need a blank dataframe for this case\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"NaN\")')\n",
        "        elif line == 'F' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-F-1077-S02_113250_F..S53X011\")')\n",
        "        elif line == 'R' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"L0S1-R-1093-S02_129650_R..N78R\")')\n",
        "        elif line == 'R' and dir == 'S':\n",
        "            # We just need a blank dataframe in this case\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"NaN\")')\n",
        "        elif line == '1' and dir == 'N':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-1092-Weekday-00_057850_1..N13R\")')\n",
        "        elif line == '1' and dir == 'S':\n",
        "            actualDf = importedDf.query('trip_id.str.contains(\"AFA23GEN-1092-Weekday-00_057950_1..S03R\")')\n",
        "\n",
        "        # Run test for each case\n",
        "        self.assertTrue(actualDf.equals(noExpressDf),\n",
        "                    \"noExpressDifferentiatedQuery does not return the expected value.\")\n",
        "\n",
        "class TestPairwiseDifferences(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_pairwiseDifferences_OutputType(self):\n",
        "    \"\"\"Test output type of pairwiseDifferences function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function.\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "    'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20', 60060, 60060],\n",
        "    'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6', 62310, 62310],\n",
        "    'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4', 62910, 62910],\n",
        "    'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12', 63570, 63570],\n",
        "    'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19', 64530, 64530],\n",
        "    'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19', 84530, 84530],\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence',  'arrival_time_sec', 'departure_time_sec']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    self.assertTrue(type(pairwiseDifferences(importedDf, 'arrival_time_sec')) == np.ndarray, \"Returned object is not a numpy array\")\n",
        "\n",
        "  # Write function\n",
        "  def test_pairwiseDifferences_OutputValue(self):\n",
        "    \"\"\"Test output value of pairwiseDifferences function.\"\"\"\n",
        "\n",
        "    # Create dataframe populated with various lines and times extracted\n",
        "    # from the given CSV file manually. This should have enough to test various cases\n",
        "    # for this function.\n",
        "    # Original dictionary\n",
        "    df = {\n",
        "    'L0S1-7-1064-S02_096800_7..S97R': ['724S', '16:41:00', '16:41:00', '20', 60060, 60060],\n",
        "    'BFA23GEN-N098-Weekday-00_103100_N..S72R': ['R08S', '17:18:30', '17:18:30', '6', 62310, 62310],\n",
        "    'BFA23GEN-N098-Weekday-00_104150_N..N33R': ['N08N', '17:28:30', '17:28:30', '4', 62910, 62910],\n",
        "    'BFA23GEN-N098-Weekday-00_103600_N..S34R': ['R16S', '17:39:30', '17:39:30', '12', 63570, 63570],\n",
        "    'BFA23GEN-N098-Weekday-00_104000_N..S72R': ['R23S', '17:55:30', '17:55:30', '19', 64530, 64530],\n",
        "    'BFA23GEN-N098-Weekday-00_104001_N..S72R': ['R23S', '17:55:30', '17:55:30', '19', 84530, 84530],\n",
        "    }\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence',  'arrival_time_sec', 'departure_time_sec']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Create resulting array (note last difference thrown out because 20000 > 7000)\n",
        "    differences = np.array([2250, 600, 660, 960])\n",
        "\n",
        "    # Test if the columns are equal\n",
        "    self.assertTrue(np.array_equal(pairwiseDifferences(importedDf, 'arrival_time_sec'), differences),\n",
        "                    \"pairwiseDifferences does not return the expected value.\")\n",
        "\n",
        "# Value not tested for this function because it compiles statistic tests, hard to know value beforehand\n",
        "class TestTrainComparison(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_trainComparison_OutputType(self):\n",
        "    \"\"\"Test output type of trainComparison function.\"\"\"\n",
        "\n",
        "    # Set inputs\n",
        "    lines = ['1', '2', '3']\n",
        "    direction = 'N'\n",
        "    rushHourType = 'morning'\n",
        "\n",
        "    # Run function and unpack tuple\n",
        "    shapWilkDict, anovapval, normal, statDf = trainComparison(lines, direction, rushHourType)\n",
        "\n",
        "    # Set types (statDf is dataframe)\n",
        "    shapWilkType = dict\n",
        "    anovapvalType = np.float64\n",
        "    normalType = bool\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    self.assertTrue(type(shapWilkDict) == shapWilkType, \"Returned object is not a dict\")\n",
        "    self.assertTrue(type(anovapval) == anovapvalType, \"Returned object is not a float\")\n",
        "    self.assertTrue(type(normal) == normalType, \"Returned object is not a float\")\n",
        "    self.assertIsInstance(statDf, pd.DataFrame, \"Returned object is not a DataFrame\")\n",
        "\n",
        "class TestStopExtractor(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_stopExtractor_OutputType(self):\n",
        "    \"\"\"Test output type of stopExtractor function.\"\"\"\n",
        "\n",
        "    # Create dictionary\n",
        "    df = {\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['101S', '00:06:00', '00:06:00', '1'],\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['103S', '00:07:30', '00:07:30', '2'],\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['104S', '00:09:00', '00:09:00', '3'],\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['106S', '00:10:30', '00:10:30', '4'],\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['107S', '00:12:00', '00:12:00', '5'],\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['108S', '00:13:00', '00:13:00', '6'],\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['109S', '00:14:30', '00:14:30', '7'],\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['110S', '00:16:00', '00:16:00', '8'],\n",
        "    'AFA23GEN-1038-Sunday-00_000600_1..S03R': ['111S', '00:17:30', '00:17:30', '9']\n",
        "    }\n",
        "\n",
        "    # Convert dictionary to dataframe\n",
        "    # Specify column names\n",
        "    columns = ['stop_id', 'arrival_time', 'departure_time', 'stop_sequence']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df).T\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.rename_axis(index='trip_id')\n",
        "\n",
        "    # Add seconds\n",
        "    secondsDf = addSeconds(importedDf, ['arrival_time', 'departure_time'])\n",
        "\n",
        "    # Run function and unpack tuple\n",
        "    secondsDf, numDict = stopExtractor(secondsDf, '1', 'S')\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    self.assertTrue(type(numDict) == dict, \"Returned object is not a dict\")\n",
        "    self.assertIsInstance(secondsDf, pd.DataFrame, \"Returned object is not a DataFrame\")\n",
        "\n",
        "  def test_stopExtractor_OutputValue(self):\n",
        "    \"\"\"Test output value of stopExtractor function.\"\"\"\n",
        "\n",
        "    # Create array\n",
        "    df = [['AFA23GEN-1038-Sunday-00_000600_1..S03R','101S', '00:06:00', '00:06:00', '1'],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','103S', '00:07:30', '00:07:30', '2'],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','104S', '00:09:00', '00:09:00', '3'],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','106S', '00:10:30', '00:10:30', '4'],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','107S', '00:12:00', '00:12:00', '5'],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','108S', '00:13:00', '00:13:00', '6'],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','109S', '00:14:30', '00:14:30', '7'],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','110S', '00:16:00', '00:16:00', '8'],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','111S', '00:17:30', '00:17:30', '9']]\n",
        "\n",
        "    dfOutput = [['AFA23GEN-1038-Sunday-00_000600_1..S03R','101S', '00:06:00', '00:06:00', '1', 360, 360, 0],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','103S', '00:07:30', '00:07:30', '2', 450, 450, 1],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','104S', '00:09:00', '00:09:00', '3', 540, 540, 2],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','106S', '00:10:30', '00:10:30', '4', 630, 630, 3],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','107S', '00:12:00', '00:12:00', '5', 720, 720, 4],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','108S', '00:13:00', '00:13:00', '6', 780, 780, 5],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','109S', '00:14:30', '00:14:30', '7', 870, 870, 6],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','110S', '00:16:00', '00:16:00', '8', 960, 960, 7],\n",
        "    ['AFA23GEN-1038-Sunday-00_000600_1..S03R','111S', '00:17:30', '00:17:30', '9', 1050, 1050, 8]]\n",
        "\n",
        "    # Specify column names\n",
        "    columns = ['trip_id', 'stop_id', 'arrival_time', 'departure_time', 'stop_sequence']\n",
        "    finalCols = ['trip_id', 'stop_id', 'arrival_time', 'departure_time', 'stop_sequence', 'arrival_time_sec', 'departure_time_sec', 'stop_val']\n",
        "\n",
        "    # Create dataframe\n",
        "    finalDf = pd.DataFrame(dfOutput)\n",
        "    finalDf.columns = finalCols\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df)\n",
        "    importedDf.columns = columns\n",
        "\n",
        "    # Add seconds\n",
        "    secondsDf = addSeconds(importedDf, ['arrival_time', 'departure_time'])\n",
        "\n",
        "    # Run function and unpack tuple\n",
        "    secondsDf, numDict = stopExtractor(secondsDf, '1', 'S')\n",
        "\n",
        "    # Write out numDict\n",
        "    numDict = {'101S':1, '103S':2, '104S':3, '106S':4, '107S':5, '108S':6, '109S':7,\n",
        "                '110S':8, '111S':9}\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    self.assertTrue(numDict == numDict, \"stopExtractor does not return the expected value\")\n",
        "    self.assertTrue(secondsDf['stop_val'].equals(finalDf['stop_val']), \"stopExtractor does not return the expected value\")\n",
        "\n",
        "class TestStopExtractor(unittest.TestCase):\n",
        "\n",
        "  # Write function\n",
        "  def test_stopIDtoName_OutputType(self):\n",
        "    \"\"\"Test output type of stopIDtoName function.\"\"\"\n",
        "\n",
        "    # Create dictionary\n",
        "    df = [('L01', '8 Av', 40.739777, -74.002578, 1),\n",
        "       ('L01N', '8 Av', 40.739777, -74.002578, ''),\n",
        "       ('L01S', '8 Av', 40.739777, -74.002578, ''),\n",
        "       ('L02', '6 Av', 40.737335, -73.996786, 1),\n",
        "       ('L02N', '6 Av', 40.737335, -73.996786, ''),\n",
        "       ('L02S', '6 Av', 40.737335, -73.996786, ''),\n",
        "       ('L03', '14 St-Union Sq', 40.734789, -73.99073, 1),\n",
        "       ('L03N', '14 St-Union Sq', 40.734789, -73.99073, ''),\n",
        "       ('L03S', '14 St-Union Sq', 40.734789, -73.99073, ''),\n",
        "       ('L05', '3 Av', 40.732849, -73.986122, 1),\n",
        "       ('L05N', '3 Av', 40.732849, -73.986122, ''),\n",
        "       ('L05S', '3 Av', 40.732849, -73.986122, ''),\n",
        "       ('L06', '1 Av', 40.730953, -73.981628, 1),\n",
        "       ('L06N', '1 Av', 40.730953, -73.981628, ''),\n",
        "       ('L06S', '1 Av', 40.730953, -73.981628, ''),\n",
        "       ('L08', 'Bedford Av', 40.717304, -73.956872, 1),\n",
        "       ('L08N', 'Bedford Av', 40.717304, -73.956872, ''),\n",
        "       ('L08S', 'Bedford Av', 40.717304, -73.956872, ''),\n",
        "       ('L10', 'Lorimer St', 40.714063, -73.950275, 1),\n",
        "       ('L10N', 'Lorimer St', 40.714063, -73.950275, ''),\n",
        "       ('L10S', 'Lorimer St', 40.714063, -73.950275, '')]\n",
        "\n",
        "\n",
        "    # Convert dictionary to dataframe\n",
        "    # Specify column names\n",
        "    columns = ['stop_id','stop_name','stop_lat','stop_lon','location_type']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df)\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.set_index('stop_id')\n",
        "\n",
        "    # Create stopID list\n",
        "    stopIDlist = ['L01N', 'L02N', 'L03N', 'L05N', 'L06N', 'L08N', 'L10N']\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    self.assertTrue(type(stopIDtoName(importedDf, stopIDlist)) == dict, \"Returned object is not a dict\")\n",
        "\n",
        "  def test_stopIDtoName_OutputValue(self):\n",
        "    \"\"\"Test output value of stopExtractor function.\"\"\"\n",
        "\n",
        "\n",
        "    # Create dictionary\n",
        "    df = [('L01', '8 Av', 40.739777, -74.002578, 1),\n",
        "       ('L01N', '8 Av', 40.739777, -74.002578, ''),\n",
        "       ('L01S', '8 Av', 40.739777, -74.002578, ''),\n",
        "       ('L02', '6 Av', 40.737335, -73.996786, 1),\n",
        "       ('L02N', '6 Av', 40.737335, -73.996786, ''),\n",
        "       ('L02S', '6 Av', 40.737335, -73.996786, ''),\n",
        "       ('L03', '14 St-Union Sq', 40.734789, -73.99073, 1),\n",
        "       ('L03N', '14 St-Union Sq', 40.734789, -73.99073, ''),\n",
        "       ('L03S', '14 St-Union Sq', 40.734789, -73.99073, ''),\n",
        "       ('L05', '3 Av', 40.732849, -73.986122, 1),\n",
        "       ('L05N', '3 Av', 40.732849, -73.986122, ''),\n",
        "       ('L05S', '3 Av', 40.732849, -73.986122, ''),\n",
        "       ('L06', '1 Av', 40.730953, -73.981628, 1),\n",
        "       ('L06N', '1 Av', 40.730953, -73.981628, ''),\n",
        "       ('L06S', '1 Av', 40.730953, -73.981628, ''),\n",
        "       ('L08', 'Bedford Av', 40.717304, -73.956872, 1),\n",
        "       ('L08N', 'Bedford Av', 40.717304, -73.956872, ''),\n",
        "       ('L08S', 'Bedford Av', 40.717304, -73.956872, ''),\n",
        "       ('L10', 'Lorimer St', 40.714063, -73.950275, 1),\n",
        "       ('L10N', 'Lorimer St', 40.714063, -73.950275, ''),\n",
        "       ('L10S', 'Lorimer St', 40.714063, -73.950275, '')]\n",
        "\n",
        "\n",
        "    # Convert dictionary to dataframe\n",
        "    # Specify column names\n",
        "    columns = ['stop_id','stop_name','stop_lat','stop_lon','location_type']\n",
        "\n",
        "    # Create dataframe from dictionary with appropriate columns\n",
        "    importedDf = pd.DataFrame(df)\n",
        "    importedDf.columns = columns\n",
        "    importedDf = importedDf.set_index('stop_id')\n",
        "\n",
        "    # Create stopID list\n",
        "    stopIDlist = ['L01N', 'L02N', 'L03N', 'L05N', 'L06N', 'L08N', 'L10N']\n",
        "\n",
        "    # Expected dict\n",
        "    stopDict = {'L01N':'8 Av', 'L02N':'6 Av', 'L03N':'14 St-Union Sq',\n",
        "                'L05N':'3 Av', 'L06N':'1 Av', 'L08N':'Bedford Av',\n",
        "                'L10N':'Lorimer St'}\n",
        "\n",
        "    # Run function and test if type is correct\n",
        "    self.assertTrue(stopIDtoName(importedDf, stopIDlist) == stopDict, \"stopDict does not return the expected value\")\n",
        "\n",
        "class TestPartOne(unittest.TestCase):\n",
        "\n",
        "  # Write function (only test output type because this function combines other\n",
        "  # functions that we already tested)\n",
        "  def test_stopIDtoName_OutputType(self):\n",
        "    \"\"\"Test output type of stopIDtoName function.\"\"\"\n",
        "\n",
        "    # Run function on one test case\n",
        "    stopDict, stopNames, timeList, time1, time2, filteredSecondsDf = partOne('1', 'N', 'morning')\n",
        "\n",
        "\n",
        "    # Test type\n",
        "    self.assertTrue(type(stopDict) == dict, \"Returned object is not a dict\")\n",
        "    self.assertTrue(type(stopNames) == dict, \"Returned object is not a dict\")\n",
        "    self.assertTrue(type(timeList) == list, \"Returned object is not a list\")\n",
        "    self.assertTrue(type(time1) == int, \"Returned object is not an int\")\n",
        "    self.assertTrue(type(time2) == int, \"Returned object is not an int\")\n",
        "    self.assertIsInstance(filteredSecondsDf, pd.DataFrame, \"Returned object is not a DataFrame\")\n",
        "\n",
        "# shapirowilk, anovatest, mannwhitneypairwise, and twosamplet are functions already written for past homeworks\n",
        "# trainIntervals, makeHeatmap, and boxAndWhisker do not return values, so they were not tested\n",
        "\n",
        "# Run test\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaK86wFmedcg",
        "outputId": "de363708-0008-49f0-bf86-5c41c70ca440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_addSeconds_OutputType (__main__.TestAddSeconds)\n",
            "Test output type of addSeconds function. ... ok\n",
            "test_addSeconds_OutputValue (__main__.TestAddSeconds)\n",
            "Test output value of addSeconds function. ... ok\n",
            "test_getSec_OutputType (__main__.TestGetSec)\n",
            "Test output type of getSec function. ... ok\n",
            "test_getSec_OutputValue (__main__.TestGetSec)\n",
            "Test output value of getSec function. ... ok\n",
            "test_noExpressDifferentiatedQuery_OutputType (__main__.TestNoExpressDifferentiatedQuery)\n",
            "Test output type of noExpressDifferentiatedQuery function. ... ok\n",
            "test_noExpressDifferentiatedQuery_OutputValue (__main__.TestNoExpressDifferentiatedQuery)\n",
            "Test output value of noExpressDifferentiatedQuery function. ... ok\n",
            "test_pairwiseDifferences_OutputType (__main__.TestPairwiseDifferences)\n",
            "Test output type of pairwiseDifferences function. ... ok\n",
            "test_pairwiseDifferences_OutputValue (__main__.TestPairwiseDifferences)\n",
            "Test output value of pairwiseDifferences function. ... ok\n",
            "test_stopIDtoName_OutputType (__main__.TestPartOne)\n",
            "Test output type of stopIDtoName function. ... ok\n",
            "test_readBullet_OutputType (__main__.TestReadBullet)\n",
            "Test output type of readBullet function. ... ok\n",
            "test_readBullet_OutputValue (__main__.TestReadBullet)\n",
            "Test output value of readBullet function. ... ok\n",
            "test_stopIDtoName_OutputType (__main__.TestStopExtractor)\n",
            "Test output type of stopIDtoName function. ... ok\n",
            "test_stopIDtoName_OutputValue (__main__.TestStopExtractor)\n",
            "Test output value of stopExtractor function. ... ok\n",
            "test_subwayLineQuery_OutputType (__main__.TestSubwayLineQuery)\n",
            "Test output type of subwayLineQuery function. ... ok\n",
            "test_subwayLineQuery_OutputValue (__main__.TestSubwayLineQuery)\n",
            "Test output value of subwayLineQuery function. ... ok\n",
            "test_subwayTimeQuery_OutputType (__main__.TestSubwayTimeQuery)\n",
            "Test output type of subwayTimeQuery function. ... ok\n",
            "test_subwayTimeQuery_OutputValue (__main__.TestSubwayTimeQuery)\n",
            "Test output value of subwayTimeQuery function. ... ok\n",
            "test_trainComparison_OutputType (__main__.TestTrainComparison)\n",
            "Test output type of trainComparison function. ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 18 tests in 2.815s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7fdb78edebc0>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partOne(line, direction, rushHourType):\n",
        "  \"\"\"Given a line, a direction, and the time of day (morning rush or evening rush),\n",
        "  returns\n",
        "  - stopDict, a dictionary corresponding each stop ID to a sequence number\n",
        "  - stopNames, a dictionary corresponding each stop ID to its street name\n",
        "  - timeList, a list of times that will serve as the x-axis of the graph depending\n",
        "  on whether it is morning rush or evening rush\n",
        "  - time1, the time in seconds corresponding to the beginning of morning or evening rush\n",
        "  - time2, the time in seconds corresponding to the  end of morning or evening rush\n",
        "  - filteredSecondsDf, a dataframe for the specific line, time of day, and rush hour type\n",
        "  with each stop arrival being listed in HH:MM:SS as well as just seconds\"\"\"\n",
        "\n",
        "  # Initializes df as a global variable (original dataframe already loaded in)\n",
        "  global df\n",
        "\n",
        "  # Runs subwayLineQuery to filter df by line and direction\n",
        "  subwayDf = subwayLineQuery(df, line, direction)\n",
        "\n",
        "  # Runs addSeconds to ensure stop times are in both HH:MM:SS and seconds\n",
        "  timeDf = addSeconds(subwayDf, ['arrival_time', 'departure_time'])\n",
        "\n",
        "  # If evening, set time1 to be the time in seconds for the beginning of evening rush,\n",
        "  # time2 to be the time in seconds for the end of evening rush, and timeList to be the\n",
        "  # list of times to be sent to the x-axis\n",
        "  if rushHourType == 'evening':\n",
        "    time1 = 55800\n",
        "    time2 = 72000\n",
        "    timeList = ['15:30', '15:45', '16:00', '16:15', '16:30', '16:45', '17:00',\n",
        "                                           '17:15', '17:30', '17:45', '18:00', '18:15', '18:30', '18:45', '19:00',\n",
        "                                           '19:15', '19:30', '19:45', '20:00']\n",
        "\n",
        "  # Do the same for morning rush\n",
        "  else:\n",
        "    time1 = 23400\n",
        "    time2 = 34200\n",
        "    timeList = ['6:30', '6:45', '7:00', '7:15', '7:30',\n",
        "                                          '7:45', '8:00', '8:15', '8:30', '8:45',\n",
        "                                          '9:00', '9:15', '9:30']\n",
        "\n",
        "  # Filter to ensure only stop times between the time for the beginning of rush and the time for\n",
        "  # the end of rush are listed\n",
        "  secondsDf = subwayTimeQuery(timeDf, 'arrival_time_sec', 'departure_time_sec', time1, time2)\n",
        "\n",
        "  # Get the stopDict for a train given direction as well the same secondsDf with an additional column\n",
        "  # containing the stop number in the sequence for the line\n",
        "  filteredSecondsDf, stopDict = stopExtractor(secondsDf, line, direction)\n",
        "\n",
        "  # Initialize global variable stopsDf\n",
        "  global stopsDf\n",
        "\n",
        "  # Get dictionary associating each stopID to its street name\n",
        "  stopNames = stopIDtoName(stopsDf, list(stopDict.keys()))\n",
        "\n",
        "  # Return values as specified\n",
        "  return stopDict, stopNames, timeList, time1, time2, filteredSecondsDf\n",
        "\n"
      ],
      "metadata": {
        "id": "zKByVgu1HPpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "YbAeg3HSSOEn",
        "outputId": "2b77f7f0-dd87-4cd5-b639-916b854d5a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            stop_id arrival_time  \\\n",
              "trip_id                                                            \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R         101S     00:06:00   \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R         103S     00:07:30   \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R         104S     00:09:00   \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R         106S     00:10:30   \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R         107S     00:12:00   \n",
              "...                                             ...          ...   \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R    S27N     25:03:00   \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R    S28N     25:06:00   \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R    S29N     25:08:00   \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R    S30N     25:10:00   \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R    S31N     25:13:00   \n",
              "\n",
              "                                            departure_time  stop_sequence  \n",
              "trip_id                                                                    \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R            00:06:00              1  \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R            00:07:30              2  \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R            00:09:00              3  \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R            00:10:30              4  \n",
              "AFA23GEN-1038-Sunday-00_000600_1..S03R            00:12:00              5  \n",
              "...                                                    ...            ...  \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R       25:03:00             17  \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R       25:06:00             18  \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R       25:08:00             19  \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R       25:10:00             20  \n",
              "SIR-FA2017-SI017-Weekday-08_147100_SI..N03R       25:13:00             21  \n",
              "\n",
              "[556275 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1eaa1fb4-60b1-4fad-bf43-9032306374ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stop_id</th>\n",
              "      <th>arrival_time</th>\n",
              "      <th>departure_time</th>\n",
              "      <th>stop_sequence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trip_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-1038-Sunday-00_000600_1..S03R</th>\n",
              "      <td>101S</td>\n",
              "      <td>00:06:00</td>\n",
              "      <td>00:06:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-1038-Sunday-00_000600_1..S03R</th>\n",
              "      <td>103S</td>\n",
              "      <td>00:07:30</td>\n",
              "      <td>00:07:30</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-1038-Sunday-00_000600_1..S03R</th>\n",
              "      <td>104S</td>\n",
              "      <td>00:09:00</td>\n",
              "      <td>00:09:00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-1038-Sunday-00_000600_1..S03R</th>\n",
              "      <td>106S</td>\n",
              "      <td>00:10:30</td>\n",
              "      <td>00:10:30</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-1038-Sunday-00_000600_1..S03R</th>\n",
              "      <td>107S</td>\n",
              "      <td>00:12:00</td>\n",
              "      <td>00:12:00</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SIR-FA2017-SI017-Weekday-08_147100_SI..N03R</th>\n",
              "      <td>S27N</td>\n",
              "      <td>25:03:00</td>\n",
              "      <td>25:03:00</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SIR-FA2017-SI017-Weekday-08_147100_SI..N03R</th>\n",
              "      <td>S28N</td>\n",
              "      <td>25:06:00</td>\n",
              "      <td>25:06:00</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SIR-FA2017-SI017-Weekday-08_147100_SI..N03R</th>\n",
              "      <td>S29N</td>\n",
              "      <td>25:08:00</td>\n",
              "      <td>25:08:00</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SIR-FA2017-SI017-Weekday-08_147100_SI..N03R</th>\n",
              "      <td>S30N</td>\n",
              "      <td>25:10:00</td>\n",
              "      <td>25:10:00</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SIR-FA2017-SI017-Weekday-08_147100_SI..N03R</th>\n",
              "      <td>S31N</td>\n",
              "      <td>25:13:00</td>\n",
              "      <td>25:13:00</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>556275 rows  4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1eaa1fb4-60b1-4fad-bf43-9032306374ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1eaa1fb4-60b1-4fad-bf43-9032306374ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1eaa1fb4-60b1-4fad-bf43-9032306374ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0def9de3-077b-4f11-bde4-0ecbba53746e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0def9de3-077b-4f11-bde4-0ecbba53746e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0def9de3-077b-4f11-bde4-0ecbba53746e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# - lineDistribution\n",
        "# Write for stopExtractor, stopIDtoName, and partOne"
      ],
      "metadata": {
        "id": "MOQLt46SKS0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(readBullet('Blue')) == [0,255]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDy4X8ZKyO-e",
        "outputId": "e84467f4-127f-4686-cd73-f03445cadd2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readBullet(line):\n",
        "  \"\"\"Give the specified train line, loads image of train bullet with OpenCV,\n",
        "  switching the R and B color channels.\"\"\"\n",
        "\n",
        "  # Access image file\n",
        "  bullet = f'/content/drive/My Drive/ENGR 1050 Final Project/02 19 Data/Bullets/{line}_Train.png'\n",
        "  imageColor = cv2.imread(bullet, cv2.IMREAD_COLOR)\n",
        "\n",
        "  if line != 'N' and line != 'Q' and line != 'R' and line != 'W':\n",
        "    # Find all black pixels (each image has a transparent background, which is loaded\n",
        "    # as black)\n",
        "    black_pixels = np.where(\n",
        "        (imageColor[:, :, 0] == 0) &\n",
        "        (imageColor[:, :, 1] == 0) &\n",
        "        (imageColor[:, :, 2] == 0))\n",
        "\n",
        "    # Set black pixels to white\n",
        "    imageColor[black_pixels] = [255, 255, 255]\n",
        "\n",
        "  # Flip R and B channels (because matplotlib does RGB instead of BGR and return flipped image)\n",
        "  imageColor_rgb = cv2.cvtColor(imageColor, cv2.COLOR_BGR2RGB)\n",
        "  return imageColor_rgb\n"
      ],
      "metadata": {
        "id": "p3E_c0tUcZeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(df).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "Fel180LYcao1",
        "outputId": "c1407688-26d0-45c6-b632-9250d49f883c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            0         1         2   3\n",
              "AFA23GEN-1038-Sunday-00_008600_1..S03R   104S  01:29:00  01:29:00   3\n",
              "AFA23GEN-1092-Weekday-00_057850_1..N13R  112N  10:20:30  10:20:30  29\n",
              "AFA23GEN-1092-Weekday-00_057950_1..S03R  113S  09:54:30  09:54:30  11\n",
              "AFA23GEN-6089-Weekday-00_075000_6..N02R  640N  12:30:00  12:30:00   1\n",
              "AFA23GEN-6089-Weekday-00_067800_6..N01R  619N  11:50:00  11:50:00  21\n",
              "AFA23GEN-6089-Weekday-00_067000_6..S03R  625S  11:35:00  11:35:00  17\n",
              "AFA23GEN-6089-Weekday-00_048500_6..S08R  608S  08:15:00  08:17:00   7\n",
              "L0S1-7-1064-S02_038300_7..S98X001        712S  06:37:00  06:37:00   6\n",
              "L0S1-7-1064-S02_038000_7..N97R           702N  06:52:00  06:52:00  21\n",
              "L0S1-7-1064-S02_096850_7..N97X005        725N  16:11:00  16:11:00   2\n",
              "L0S1-7-1064-S02_096800_7..S97R           724S  16:41:00  16:41:00  20\n",
              "L0S1-F-1077-S02_113250_F..S53X011        F35S  20:16:30  20:20:00  40\n",
              "L0S1-R-1093-S02_129650_R..N78R           R44N  21:38:30  21:38:30   2\n",
              "BFA23GEN-N098-Weekday-00_103100_N..S72R  R08S  17:18:30  17:18:30   6\n",
              "BFA23GEN-N098-Weekday-00_104000_N..S72R  R23S  17:55:30  17:55:30  19\n",
              "FA23GEN-N098-Weekday-00_104150_N..N33R   N08N  17:28:30  17:28:30   4\n",
              "BFA23GEN-N098-Weekday-00_103600_N..S34R  R16S  17:39:30  17:39:30  12"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1a3550a-58b6-406a-b870-f67ac2b012fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-1038-Sunday-00_008600_1..S03R</th>\n",
              "      <td>104S</td>\n",
              "      <td>01:29:00</td>\n",
              "      <td>01:29:00</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-1092-Weekday-00_057850_1..N13R</th>\n",
              "      <td>112N</td>\n",
              "      <td>10:20:30</td>\n",
              "      <td>10:20:30</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-1092-Weekday-00_057950_1..S03R</th>\n",
              "      <td>113S</td>\n",
              "      <td>09:54:30</td>\n",
              "      <td>09:54:30</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-6089-Weekday-00_075000_6..N02R</th>\n",
              "      <td>640N</td>\n",
              "      <td>12:30:00</td>\n",
              "      <td>12:30:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-6089-Weekday-00_067800_6..N01R</th>\n",
              "      <td>619N</td>\n",
              "      <td>11:50:00</td>\n",
              "      <td>11:50:00</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-6089-Weekday-00_067000_6..S03R</th>\n",
              "      <td>625S</td>\n",
              "      <td>11:35:00</td>\n",
              "      <td>11:35:00</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFA23GEN-6089-Weekday-00_048500_6..S08R</th>\n",
              "      <td>608S</td>\n",
              "      <td>08:15:00</td>\n",
              "      <td>08:17:00</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L0S1-7-1064-S02_038300_7..S98X001</th>\n",
              "      <td>712S</td>\n",
              "      <td>06:37:00</td>\n",
              "      <td>06:37:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L0S1-7-1064-S02_038000_7..N97R</th>\n",
              "      <td>702N</td>\n",
              "      <td>06:52:00</td>\n",
              "      <td>06:52:00</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L0S1-7-1064-S02_096850_7..N97X005</th>\n",
              "      <td>725N</td>\n",
              "      <td>16:11:00</td>\n",
              "      <td>16:11:00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L0S1-7-1064-S02_096800_7..S97R</th>\n",
              "      <td>724S</td>\n",
              "      <td>16:41:00</td>\n",
              "      <td>16:41:00</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L0S1-F-1077-S02_113250_F..S53X011</th>\n",
              "      <td>F35S</td>\n",
              "      <td>20:16:30</td>\n",
              "      <td>20:20:00</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L0S1-R-1093-S02_129650_R..N78R</th>\n",
              "      <td>R44N</td>\n",
              "      <td>21:38:30</td>\n",
              "      <td>21:38:30</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BFA23GEN-N098-Weekday-00_103100_N..S72R</th>\n",
              "      <td>R08S</td>\n",
              "      <td>17:18:30</td>\n",
              "      <td>17:18:30</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BFA23GEN-N098-Weekday-00_104000_N..S72R</th>\n",
              "      <td>R23S</td>\n",
              "      <td>17:55:30</td>\n",
              "      <td>17:55:30</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FA23GEN-N098-Weekday-00_104150_N..N33R</th>\n",
              "      <td>N08N</td>\n",
              "      <td>17:28:30</td>\n",
              "      <td>17:28:30</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BFA23GEN-N098-Weekday-00_103600_N..S34R</th>\n",
              "      <td>R16S</td>\n",
              "      <td>17:39:30</td>\n",
              "      <td>17:39:30</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1a3550a-58b6-406a-b870-f67ac2b012fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1a3550a-58b6-406a-b870-f67ac2b012fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1a3550a-58b6-406a-b870-f67ac2b012fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-938b0fa9-4a09-4af7-af3e-00af60b8b5f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-938b0fa9-4a09-4af7-af3e-00af60b8b5f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-938b0fa9-4a09-4af7-af3e-00af60b8b5f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 17,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"104S\",\n          \"112N\",\n          \"625S\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"01:29:00\",\n          \"10:20:30\",\n          \"11:35:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"01:29:00\",\n          \"10:20:30\",\n          \"11:35:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"20\",\n          \"19\",\n          \"3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}